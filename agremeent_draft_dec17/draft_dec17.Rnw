\documentclass[doc,a4paper,man,natbib,floatsintext,noextraspace]{apa6}
<<echo=F>>=
# Set the global chunk options
set.seed(42)
knitr::opts_chunk$set(encoding = 'UTF-8',
                      cache.extra = knitr::rand_seed,
                      echo = F,
                      results = 'hide',
                      message = F,
                      warning = F)
options("citation_format" = "pandoc")
@

<<setup, echo=FALSE, cache=FALSE>>=
## numbers >= 10^5 will be denoted in scientific notation,
## and rounded to 2 digits
options(scipen = 1, digits = 2)
@

\usepackage[english]{babel}
\usepackage[utf8x]{inputenc}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{graphicx}
\usepackage[colorinlistoftodos]{todonotes}
\usepackage[singlespacing]{setspace}
<<>>=
# load packages
library(patchSynctex)
library(knitcitations)
library(car, warn.conflicts = FALSE)
library(MASS)
library(brms)
library(xtable)
library(ggpubr)
library(languageR)
library(tidyverse)
library(gdata)
library(magrittr)
library(ggplot2)
theme_set(theme_bw())

source("../scripts/misc.R")

@
\title{The Role of Shallow Processing in Agreement Attraction}
\shorttitle{Your APA6-Style Manuscript}
\author{Utku Türk, Pavel Loga\v{c}ev}
\affiliation{Boğaziçi University}


\abstract{We report the results of two speeded acceptability judgment experiments in Turkish. We hypothesized an alternative explanation for agreement attraction effects in Turkish that is based on shallow processing. Our findings contradict our hypothesized form-driven processing strategy and support an account of agreement attraction based on the use of abstract linguistic features, rather than mere form.}

\input{settings.tex}

\begin{document}

\maketitle


\section{Introduction} \label{sec:Intro}

%\footnote{\printglossaries}. % add this to somewhere in the first page I suppose

\subsection{Agreement Attraction Thingy} \label{sec:Intro:literature}

\subsubsection{Morphophonology} \label{sec:Intro:literature:morphophonology}

%fill here accordingly to your results AFTER YOU WRITE THE RESULT.


\subsubsection{related sub-sub-field studies} \label{sec:Intro:literature:others}

\subsubsection{This work details} \label{sec:Intro:literature:thiswork}

% \citet{LagoEtAl:2018} hypothesize that genitive NPs can trigger agreement attraction in Turkish, because Turkish makes heavy use of genitive subjects, which means genitives are a priori likely to function as agreement controllers. The underlying assumption is that agreement processes rely on, at least partially, the case of an NP to determine its fit for the role of an agreement controller. 
% If that is so, their items are problematic %as in ... give an example
% in that the marking on the head noun is ambiguous between possessive and accusative case, while only possessive-marked NPs qualify as agreement controllers. Therefore, if engaged in shallow processing, readers may be more likely to misidentify the genitive NP as the agreement controller when the head noun, which is the only other alternative, is ambiguous, compared to when it is not.

% In Experiment 1, we decided to test this hypothesis 




\section{Experiment 1} \label{sec:exp1}

% do not do this in one chunk. differentiate the chunks and give them proper names.
<<>>=
fname_data <- "../workspace_exp1/exp_data.rds"
data_exp1 <- readRDS(fname_data)
fname_form <- "../workspace_exp1/exp_form.rds"
form_exp1 <- readRDS(file = fname_form)
form_exp1[106,2] = 18 # manually changed on sekiz to 18

### note: the low accuracy on fillers is not caused by a couple of items
# filler_avgs <- 
# data_exp1 %>% subset(Type == "filler") %>% group_by(Item, condition) %>% 
#               summarize(M = mean(ResponseYes, na.rm = T)) %>%
#               arrange(condition, Item)
# fillers %>% subset(condition == "a") 
# fillers %>% subset(condition == "b")
###

# compute by-subject percentages of 'yes' responses, and average RTs 
avg_by_subj <- data_exp1 %>%
                group_by(subject, experiment, condition, 
                         grammatical, verb_num, attractor_num) %>%
                summarize(avRT = mean(RT), 
                          p_yes = mean(ResponseYes, na.rm = T), 
                          N = sum(!is.na(ResponseYes))  )

# reformat by-subject averages to a wide format
avg_by_subj_wide <- avg_by_subj %>% 
                      mutate(expcond = paste(experiment, condition, sep="_")) %>% 
                      ungroup() %>%
                      dplyr::select(-experiment, -condition, -avRT, -N,
                                    -grammatical, -verb_num, -attractor_num) %>%
                      tidyr::spread(expcond, p_yes) %>% 
                      mutate(delta_dc = AgrAttr_d - AgrAttr_c)


# Load Lago et al.'s monolingual data
fname_lagoetal <- "../Data/Lago_et_al/Lago_data.csv"
df_lagoetal <- read.csv(fname_lagoetal, encoding = "UTF-8", as.is = T)
df_lagoetal %<>% subset(Group == "monolingual")
df_lagoetal %<>% dplyr::select(-Accuracy, -L1:-Group, -List:-SelfRateGerman)

# Note: All rows with Experiment == "offline" also seem to be for 
#       the UNP task ('Grammatical' is NA). I wonder if these were
#       the same subjects, or if the subject labels were simply the same
#       for the two experiments.
with(df_lagoetal, stopifnot( is.na(Grammatical) == (Experiment == "offline") ))

df_lagoetal_unp <- df_lagoetal %>% 
                    subset(is.na(Grammatical)) %>%
                    dplyr::select(-Grammatical:-Label)
df_lagoetal_attr <- df_lagoetal %>% 
                  subset(!is.na(Grammatical)) %>%
                  dplyr::select(-Distance:-NewCond)

df_lagoetal_attr %<>% mutate(ResponseYes = (Response == "yes") ) %>% 
                      dplyr::select(-Response)
df_lagoetal_attr %<>% ungroup() %>%
                      dplyr::select(grammatical=Grammatical,
                                    attractor_num=Attractor,
                                    experiment=Experiment,
                                    lagoetal_condition=Condition, 
                                    subject=Participant, 
                                    item=Item,
                                    ResponseYes,
                                    RT)

# map to our condition labels
lagoetal_condition_mapping <- data.frame(
    condition = c("a", "b", "c", "d"),
    lagoetal_condition = c("d", "b", "c", "a"), 
    stringsAsFactors = F)

df_lagoetal_attr %<>% left_join( lagoetal_condition_mapping, by = "lagoetal_condition" )

# compute by-subject percentages of 'yes' responses, and average RTs 
avg_by_subj_lagoetal <- df_lagoetal_attr %>%
            group_by(subject, experiment, condition, grammatical, attractor_num) %>%
            summarize(avRT = mean(RT), 
                      p_yes = mean(ResponseYes, na.rm = T), 
                      N = sum(!is.na(ResponseYes))  )

# reformat by-subject averages to a wide format
avg_by_subj_lagoetal_wide <- avg_by_subj_lagoetal %>% 
            mutate(expcond = paste(experiment, condition, sep="_")) %>% 
            ungroup() %>%
            dplyr::select(-experiment, -condition, -avRT, -N,
                          -grammatical, -attractor_num) %>%
            tidyr::spread(expcond, p_yes) %>% 
            mutate(delta_dc = online_d - online_c)
word_freq <- readxl::read_excel("../Data/freq.xlsx", sheet = 1)
word_freq$freq_percentage %<>% as.numeric()
word_freq %<>% dplyr::select(-freq_standardized, -freq_percentage, -word)
word_freq %<>% tidyr::spread(place, freq_count)

word_freq %<>% dplyr::group_by(exp) %>% 
               dplyr::mutate( cat_n1 = ifelse(n1 > median(n1), "high", "low"),
                              cat_n2 = ifelse(n2 > median(n2), "high", "low"),
                              freqlog_n1 = scale(log(n1)),
                              freqlog_n2 = scale(log(n2)),
                              freqlog_n1n2 = log(n1) - log(n2)
                            ) %>% 
                ungroup()
word_freq$cat_n1 %<>% as.factor()
word_freq$cat_n2 %<>% as.factor()

word_freq_exp1 <- word_freq %>% 
                    subset(exp == "up") %>% 
                    dplyr::select(-exp)
word_freq_lago <- word_freq %>% 
                    subset(exp == "lago") %>% 
                    dplyr::select(-exp)

# identify bad participants 
bad_subjects <- subset(avg_by_subj_wide, delta_dc <= 0.25 ) %>% .$subject
data_exp1_clean <- data_exp1 %>% subset(!subject %in% bad_subjects)

# identify bad participants 
bad_subjects_lagoetal <- subset(avg_by_subj_lagoetal_wide, delta_dc <= 0.25 ) %>% .$subject
df_lagoetal_attr_clean <- df_lagoetal_attr %>% subset(!subject %in% bad_subjects_lagoetal)
df_merge_exp1 <- data_exp1_clean %>% ungroup() %>% 
                      dplyr::select(source=experiment, 
                                    grammatical, attractor_num,
                                    # condition,
                                    subject, item=Item,
                                    ResponseYes, RT)
df_merge_exp1$experiment <- "Experiment 1"
df_merge_exp1$grammatical <- with(df_merge_exp1, 
                                  ifelse(grammatical == "gram", 
                                          "grammatical",
                                          "ungrammatical"))
df_merge_exp1$attractor_num <- with(df_merge_exp1, 
                                    ifelse(attractor_num == "pl",
                                           "plural", 
                                           "singular"))
df_merge_exp1$item %<>% as.integer()
df_merge_exp1$subject %<>% as.character()
#df_merge_exp1 %<>% left_join(word_freq_exp1, by = "item")

df_merge_lago <- df_lagoetal_attr_clean %>%
                      ungroup() %>% 
                      dplyr::select(grammatical, attractor_num,
                                    subject, item, ResponseYes, RT)
#df_merge_lago %<>% left_join(word_freq_lago, by = "item")
df_merge_lago$experiment <- "Lago et al. (2018)" 
df_merge_lago$source <- NA
df_merge_lago$item %<>% add(1000)

df_merged <- dplyr::bind_rows(df_merge_exp1, df_merge_lago)
df_merged$subject %<>% as.factor()
df_merged$item %<>% as.factor()

df_exp1_na_nofillers <- subset(df_merge_exp1, is.na(ResponseYes) & source != "filler")
df_merged %<>% subset( !is.na(ResponseYes) )

@

In Experiment 1, we tested whether speakers of Turkish make fewer errors when the local ambiguity in the head noun is resolved. Specifically, we have replicated the \citet{LagoEtAl:2018} study. However, instead of using their NP heads, we chose to use nouns that end in a vowel, thus resolving the ambiguity between the accusative and possessive. 

\subsection{Participants} \label{sec:exp1:participants}

One hundred seven native speakers of Turkish in Experiment 1. The mean age is \Sexpr{mean(as.numeric(as.character(form_exp1$Age)))}, ranging from \Sexpr{min(as.numeric(as.character(form_exp1$Age)))} to \Sexpr{max(as.numeric(as.character(form_exp1$Age)))}. Across participants, a total \Sexpr{sum(is.na(df_exp1_na_nofillers$ResponseYes))} items were not responded to before the 5 second deadline by \Sexpr{length(unique(df_exp1_na_nofillers$subject))} different participants. These items were not included in the analysis. Experiments in this paper were carried out following the Declaration of Helsinki and the regulations concerning ethics in research in Bo\u{g}azi\c{c}i University. All participants provided informed consent. They were tested online, on IbexFarm, using their preferred platform. 

\subsection{Materials} \label{sec:exp1:materials}

In Experiment 1, participants first saw sentences word by word in the middle of their screen. As in \citet{LagoEtAl:2018} study, we used 40 sets of item and manipulated the grammaticality of the sentences (\textit{grammatical} x \textit{ungrammatical}) and the number of the attractor noun (\textit{singular} x \textit{plural}). All experimental sentences followed the following template: \textit{Noun$_{{\textsc{gen}}}$-Noun$_{{\textsc{poss}}}$-Adverb-Verb}. The distribution of the verb types followed the same pattern as in \citet{LagoEtAl:2018}, namely twenty unergatives, eighteen unaccusatives, and two optionally transitive verbs. The matrix verb was marked with overt plural marker \textit{-lar} in the half of experimental items. Adverbials in our experimental sentences were always pre-verbal and contained 2-3 words consisting of 15 characters on average. The second noun phrase is the head noun of the subject in all of our experimental sentences whereas the first noun phrase is the genitive modifier of the head, thus \textit{the attractor}. Unlike \citet{LagoEtAl:2018}, our head nouns were vowel-ending, which enables us to distinguish between accusative (\textit{-yI}) and possessive (\textit{-sI}). This change was due to the morpho-phonologic nature of possessive suffix in Turkish, which spell-outs as (\textit{-I}) after a consonant same as the accusative. While all of the head nouns were singular, the attractor noun was in its plural form in the half of the experimental items. One example set of experimental items can be seen in \ref{item:exp1ExperimentalItems}.

% there may be a better way of displaying items.
\ex. \label{item:exp1ExperimentalItems}
\a. \textit{Plural Attractor, Ungrammatical Verb} \label{item:exp1expitem-plpl}\\ 
\gll *Yönetici-ler-in aşcı-sı mutfak-ta sürekli zıpl-ıyor-lar.\\ 
manager-\textsc{pl}-\textsc{gen}  cook-\textsc{poss} kitchen-\textsc{loc} non-stop  jump-\textsc{prog}-\textsc{pl}.\\
\glt `The cooks of the manager were jumping in the kitchen non-stop.' 
\b. \textit{Singular Attractor, Ungrammatical Verb} \label{item:exp1expitem-sgpl}\\ 
\gll *Yönetici-nin aşcı-sı mutfak-ta sürekli zıpl-ıyor-lar.\\ 
manager-\textsc{gen}  cook-\textsc{poss} kitchen-\textsc{loc} non-stop  jump-\textsc{prog}-\textsc{pl}.\\
\glt `The cook of the manager were jumping in the kitchen non-stop.'
\c. \textit{Plural Attractor, Grammatical Verb} \label{item:exp1expitem-plsg}\\ 
\gll Yönetici-ler-in aşcı-sı mutfak-ta sürekli zıpl-ıyor.\\ 
manager-\textsc{pl}-\textsc{gen}  cook-\textsc{poss} kitchen-\textsc{loc} non-stop  jump-\textsc{prog}.\\
\glt `The cooks of the manager was jumping in the kitchen non-stop.'
\d. \textit{Singular Attractor, Grammatical Verb}\label{item:exp1expitem-sgsg}\\ 
\gll Yönetici-nin aşcı-sı mutfak-ta sürekli zıpl-ıyor. \\ 
manager-\textsc{gen}  cook-\textsc{poss} kitchen-\textsc{loc} non-stop  jump-\textsc{prog}.\\
\glt `The cook of the manager was jumping in the kitchen non-stop.'

As for the filler sentences, we have included forty sentences, half of which ends in singular and ungrammatical while the other half was plural and grammatical. These decisions were made due to the non-existence of such sentences in the experimental sentences. We wanted to rule out a possible task strategy where participants decide on the grammaticality of the sentence by merely checking the final plural marking. Even though filler items did not follow a strict template as the experimental items, they were created within a template of \textit{Noun$_{{\textsc{gen}}}$-Noun$_{{\textsc{gen}}}$-Converb-Noun-Adverb-Verb}. The ungrammaticality was created non-locally in the filler items to avoid task strategies. Example filler sentences can be seen in \ref{item:exp1FillerItems}.


\ex. \label{item:exp1FillerItems}
\a. \textit{Plural Grammatical Verb}\\ 
\gll Sosyolog-un öğrenci-si konuş-unca tutarsızlık açığ-a çıkar-dı-lar.\\ 
sociolog-\textsc{gen}  student-\textsc{poss} speak-\textsc{nmlz} inconsistency  open-\Dat{} deduct-\textsc{pst}-\textsc{pl}.\\
\glt `When the sociolog's student talked, they exposed an inconsistency.' 
\b. \textit{Singular Ungrammatical Verb}\\ 
\gll *Dansöz-ün koca-sı var-ınca kapı sakince aç-tı.\\ 
dancer-\textsc{gen}  husband-\textsc{poss} arrive-\textsc{nmlz} door slowly  open-\textsc{pst}.\\
\glt Intended:`When the husband of the dancer came, the door opened slowly.'

\subsection{Procedure} \label{sec:exp1:procedure}

Prior to the experiments, participants gave information regarding themselves and consent to participate in the experiment. They read the instructions where we showed what they will see in the experiment, and where we informed them to give quick and accurate answers during the experiment. They are also informed regarding the that there will be a time-limit in answering the question. Every session started with a practice session where participants have been informed to be a bit faster when they were not. The sentences were presented in the middle of the screen word-by-word on a web-based platform Ibex Farm (\url{http://spellout.net/ibexfarm/}). Each word was displayed with 30 font size and stayed on the screen for 300 ms, unlike \citet{LagoEtAl:2018} and \citet{WagersEtAl:2009} where words stayed for 500 ms in the screen. After the sentence is completed, participants were asked: "How did they find the sentence?" They were informed to press P on their keyboard for \textit{good} and Q for bad. Apart from the practice items, we did not provide any feedback regarding their answers. However, participants were instructed to be faster when they waited more than 5,000 ms to answer the acceptability question. 

Participants saw forty experimental and forty filler items. Experimental items were distributed among four different lists using Latin Square design. Every participant saw one version of the experiment with a specific list and one item per condition.   

\subsection{Analysis} \label{sec:exp1:analysis}
% Maybe leave it to Pavel?

Every experimental item from both experiments (Experiment 1 and \citet{LagoEtAl:2018}) is included in the analysis. Participants (\Sexpr{length(bad_subjects)}) that exceeded the threshold of 0.25 difference in giving accurate answers to grammatical conditions \ref{item:exp1expitem-sgsg} and \ref{item:exp1expitem-sgpl} are excluded from the analysis. We used R packages brms \citep{R-brms_b} and rstan \citep{R-stan} to fit Bayesian hierarchical models \citep{GelmanHill:2007}. We added our independent variables, i.e. grammaticality of the sentence and the overt number information on the distractors, and random variable experiment as a factor. Analyses by items and participants are also conducted as a part of the Bayesian hierarchical models. We added our independent variables, i.e. grammaticality of the sentence and the overt number information on the distractors, and random variable experiment as a factor. Analyses by items and participants are also conducted as a part of the Bayesian hierarchical models.
%I did not know how to state (1+x*y|subjet)
Data regarding our experiments and analysis can be found in \texttt{link hidden due to blind review}.



\subsection{Results} \label{sec:exp1:results}

<<>>=

df_merged %<>% mutate(ResponseCorrect = (ResponseYes == (grammatical == "grammatical") ) )
df_merged_nonna <- df_merged %>% subset(!is.na(ResponseYes))

# avg_clean <- 
# df_merged %>% subset(experiment == "Lago et al. (2018)") %>%
#      group_by(experiment, source, grammatical, attractor_num, subject) %>%
#      summarize(p_yes = mean(ResponseYes, na.rm=T)) %>%
#      summarize(p_yes = mean(p_yes))



avg_clean <- list()
avg_clean$resp <- df_merged_nonna %>% 
              plyr::ddply(c("experiment"), function(df) {
              df %>% se_cousineau(n_conditions = 4, subject, DV = ResponseYes, 
                           group = c("experiment", "source", "grammatical", "attractor_num"), 
                           is_proportion = TRUE)
})

avg_clean$rt <- df_merged_nonna %>%
              plyr::ddply(c("experiment"), function(df) {
              df %>% se_cousineau(n_conditions = 4, subject, DV = RT, 
                           group = c("experiment", "source", "grammatical", "attractor_num"), 
                           is_proportion = FALSE)
})

avg_clean$rt_correct <- df_merged_nonna %>% subset(ResponseCorrect) %>%
              plyr::ddply(c("experiment"), function(df) {
              df %>% se_cousineau(n_conditions = 4, subject, DV = RT, 
                           group = c("experiment", "source", "grammatical", "attractor_num"), 
                           is_proportion = FALSE)
})

avg_exp <- avg_clean %>% lapply(function(df) { df %>% subset(is.na(source) | source != "filler") })
avg_fillers <- avg_clean %>% lapply(function(df) { df %>% subset(source == "filler") })
pd <- position_dodge(0.1)
p_avg_resp <- avg_exp$resp %>%
              ggplot(aes(grammatical, M, #linetype = attractor_num, 
                         color = attractor_num, group = attractor_num)) + 
                geom_point(position = pd) + geom_line(position = pd) + 
                facet_wrap(~experiment)

p_avg_resp <- p_avg_resp + geom_errorbar(aes(ymin = M - 1.96*SE, ymax = M + 1.96*SE), width = 0.1, position = pd)

# p_avg_resp <- p_avg_resp + geom_line(data = avg_fillers) + 
#                             geom_point(data = avg_fillers) + 

p_avg_resp <- p_avg_resp + theme( strip.background = element_rect(fill="white") ) +
                           theme_bw() + xlab("") + ylab("Percentage 'acceptable'")
p_avg_resp <- p_avg_resp + scale_y_continuous(labels=scales::percent)#, breaks = c(0, .25, .5, .75, 1))
p_avg_resp <- p_avg_resp + theme_bw()
p_avg_resp <- p_avg_resp + scale_color_discrete(name = "Attractor Number")

@

\autoref{fig:exp1AvgResponse} shows the average proportions of ‘acceptable’ responses by experimental condition for both the original experiment in \citet{LagoEtAl:2018} and our replication with unambiguous possessive marking. It shows that ungrammatical sentences with plural attractors are rated as acceptable more often (M = \Sexpr{avg_exp$resp$M[3]}\%, SE = \Sexpr{avg_exp$resp$SE[3]}\%) than their counterparts with singular attractors (M=\Sexpr{avg_exp$resp$M[4]}\%, SE=\Sexpr{avg_exp$resp$SE[4]}\%). In addition to ungrammatical conditions, accuracy rates within the grammatical conditions were comparable and high across conditions (M = \Sexpr{avg_exp$resp$M[1]}\% and \Sexpr{avg_exp$resp$M[2]}\%, SE = \Sexpr{avg_exp$resp$SE[1]}\% and \Sexpr{avg_exp$resp$SE[2]}\% for singular and plural attractors respectively). As seen in \autoref{fig:exp1AvgResponse}, participants judged the sentences with plural attractor and singular verbs to be grammatical with the rate of \Sexpr{avg_exp$resp$M[3]-avg_exp$resp$M[4]}\%, which is in line with the findings reported in \citet{LagoEtAl:2018}.    


<<exp1AvgResponse, fig.cap='Percentage of \\emph{yes} (acceptable) responses of Experiment 1 and \\citet{LagoEtAl:2018}', fig.height=3, fig.align='center'>>=
print(p_avg_resp)

@

<<exp1models, include=FALSE>>=

df_merged %<>% within(., {
  cGrammatical <- ifelse(grammatical == "grammatical", .5, -.5)
  cUngrammatical <- ifelse(grammatical == "ungrammatical", .5, -.5)
  cAttractorPlural <- ifelse(attractor_num == "plural", .5, -.5)
  cEndsInConsonant <- ifelse(experiment != "Experiment 1", .5, -.5)
  #cFreqlog_n1n2 <- scale(freqlog_n1n2)
  #cFreqlog_n1 <- scale(freqlog_n1)
  #cFreqlog_n2 <- scale(freqlog_n2)
})
df_merged_nofillers <- df_merged %>% subset(is.na(source) | source != "filler")

# ## test model parameterization using a simple GLM first
# m <- glm(ResponseYes ~ (cFreqlog_n1 + cFreqlog_n2) *
#            cEndsInConsonant * cUngrammatical * cAttractorPlural,
#          data = df_merged_nofillers,
#          family = binomial("probit"))
# summary(m)

n_chains <- 4
n_cores <- 4
n_iter <- 2000


fname_exp1_responses <- "../workspace_exp1/model_responses"
m_responses <- brm(ResponseYes ~ cEndsInConsonant * cUngrammatical * cAttractorPlural + 
                                 (cUngrammatical * cAttractorPlural + 1| subject) + 
                                 (cUngrammatical * cAttractorPlural + 1| item),
                   data = df_merged_nofillers,
                   family = bernoulli("probit"),
                   file = fname_exp1_responses, 
                   chains = n_chains, cores = n_cores, iter = n_iter)


fname_exp1_responses_minimal <- "../workspace_exp1/model_responses_minimal"
m_responses_minimal <- brm(ResponseYes ~ (cEndsInConsonant + cUngrammatical + cAttractorPlural)^2 + 
                                         (cUngrammatical * cAttractorPlural + 1| subject) +
                                         (cUngrammatical * cAttractorPlural + 1| item),  #Can we omit this one out? We do not have every condition for every item from each subject? It goes to minus infinity.
                   data = df_merged_nofillers,
                   family = bernoulli("probit"),
                   file = fname_exp1_responses_minimal, 
                   chains = n_chains, cores = n_cores, iter = n_iter)


fname_exp1_rts <- "../workspace_exp1/model_responses_rt"
m_rts <- brm(RT ~ cEndsInConsonant * cUngrammatical * cAttractorPlural +
                                 (cUngrammatical * cAttractorPlural + 1| subject) +
                                 (cUngrammatical * cAttractorPlural + 1| item),
                   data = df_merged_nofillers,
                   family = lognormal(),
                   file = fname_exp1_rts,
                   chains = n_chains, cores = n_cores, iter = n_iter)

model_results_table <- fixef(m_responses, summary = T, robust = F) %>% 
  as.data.frame() %>% tibble::rownames_to_column("variables")
@

The estimates and 95\% CIs of a Bayesian GLM in \autoref{fig:exp1ResponseModel} confirm the observations we stated above: the positive interaction between sentence grammaticality and attractor number is in line with a larger effect of attractor number in ungrammatical sentences. The main effect of ungrammaticality was \Sexpr{model_results_table[3,2]}[\Sexpr{model_results_table[3,4]};\Sexpr{model_results_table[3,4]}] in log-odds, and the interaction between the ungrammaticality and plural attractor was \Sexpr{model_results_table[7,2]}[\Sexpr{model_results_table[7,4]};\Sexpr{model_results_table[7,5]}] in log-odds. Since other estimates' credible intervals range over zero, we conclude that they were not informative. %maybe speak with p values? 
% we did not do any nested analysis, should we? Should it say anything different than figure 2? 

%Moreover, this findings are also predicted by cue-based retrieval models \citep{engelmann2019effect, vasishth2019computational} and last rendition of marking and morphing theory by \citet{HammerlyEtAl:2019}. %does it tho? especially with regards to what sol lago says: gen and morphophonology gives clues. maybe we should take a look at speeded acceptability? 
%maybe this is not the perfect place to write this.



<<exp1ResponseModel, fig.cap='Estimates and 95\\% credible intervals for the regression coefficients for Experiment 1', fig.height=3, fig.align='center'>>=
contrast_names <- c("cUngrammatical" = "Ungrammaticality",
                    "cAttractorPlural" = "Plural Attactor",
                    "cUngrammatical:cAttractorPlural" = "Ungrammaticality * Plural Attractor",
                    "cEndsInConsonant" = "Ambiguity",
                    "cEndsInConsonant:cUngrammatical" = "Ambiguity * Ungrammaticality",
                    "cEndsInConsonant:cAttractorPlural" = "Ambiguity * Plural Attractor",
                    "cEndsInConsonant:cUngrammatical:cAttractorPlural" = "Ambiguity * Ungrammaticality * Plural Attractor")

p_m_response <- 
  create_model_coefs_plot( m_responses, 
        plot_stats = T, map_names = contrast_names,
        expand_right = 2.5, expand_top = 2, x_stat_adjust = 1.1,
        x_breaks = c(-3,-2,-1, 0,1, 2) ) + 
        xlab("Estimate (log-odds)")

suppressWarnings({
print(p_m_response + annotate(x=-3, xend=2, y=0, yend=0, lwd=0.25, geom="segment"))
})

@



\subsection{Discussion} \label{sec:exp1:discussion}

In Experiment 1, we have found number attraction effects in Turkish using genitive possessive structures, as it is also attested in \citet{LagoEtAl:2018}. To account for their findings, \citet{LagoEtAl:2018} assume a cue-based memory retrieval mechanism. That is, they assume that upon reaching the verb, the parser attempts to retrieve its agreement controller (the subject) using a cue-based retrieval mechanism \citep{LewisVasishth:2005,JagerEngelmannVasishth:2017}. The assumption is that in sentences such as \ref{item:exp1ExperimentalItems}, features such as case and number information are used to identify the agreement controller in memory. In ungrammatical sentences, when the verb bears plural agreement, no NP in memory will match both retrieval cues. However, in ungrammatical plural attractor conditions, the attractor matches one of the cues, which can lead to its erroneous retrieval on some occasions. This cannot happen in ungrammatical singular attractor conditions. This difference in the probability of erroneous retrievals is presumably what surfaced as a number agreement attraction effect, as observed in \citet{LagoEtAl:2018}, and our Experiment 1.

In their work, \citet{LagoEtAl:2018} argue that the agreement attraction in genitive-possessive structures in Turkish is due to the use of genitive case as a marker of embedded subjects in Turkish, i.e. differential subject marking (DSM) properties of Turkish \citep{kornfilt2009dom}. They argue that the genitive case in Turkish may not provide strong cue against subjecthood due to DSM while it does in English. Following this logic, we hypothesized that the other phenomenon that gives a strong clue against the subject should inhibit the illusionary dependencies as argued in \citet{nicol2016minimal}. One such phenomenon was present in the experimental items used in \citet{LagoEtAl:2018}: the morpho-phonologic ambiguity between the accusative and the possessive case. Since they use only consonant ending heads, the marking on the head is ambiguous between the accusative and the possessive marking. Following their argumentation, participants may search for other agreement controllers than the possessive marked heads when they are engaged in shallow processing and erroneously assign head as genitive marked distractor.

Nevertheless, we found that when the possessive marker is disambiguated agreement attraction does not diminish in effect size. As seen in \autoref{fig:exp1ResponseModel}, we successfully replicated the findings of \citet{LagoEtAl:2018} with disambiguated head nouns. Thus, we conclude that the morpho-phonological possessive-accusative ambiguity plays no role in number attraction in Turkish.


However, there is an alternative explanation that has yet to be ruled out: task-specific strategies. We hypothesized that readers may engage in an even shallower process in the evaluation of the sentences such as \ref{item:exp2ExperimentalItems} in which readers decide on the acceptability of the sentence with a faulty state of memory. In our model, we claim that after they read the sentence readers may end up with insufficient information to reliably judge the sentence. Upon such cases, readers may end up using extremely shallow processing methods such as matching the agreement-wise unrelated but form-wise related elements. % I should try a bit more to explain this part, I did not do a good job here.
We present our hypothesized decision tree in \autoref{fig:mptModel}

\begin{figure}[h]
    \centering
                      \begin{forest}
                  for tree = {
                  % nodes
                      draw, 
                      align=center,
                      minimum height=5ex,
                      minimum width=3em,
                      font=\linespread{0.84}\selectfont,
                  % tree
                      grow'=0,
                      parent anchor=east,
                      child  anchor=west,
                      s sep = 4mm,    
                      l sep = 12mm, 
                  % edge
                      edge = {semithick},
                  % level styles
                  if level = 0{}{rounded corners=2ex},
                  where n children=0{tier=level, sharp corners}{calign=edge midpoint},
                  % edge labels
                  EL/.style={edge label={node [pos=0.5, fill=white,
                                               font=\scriptsize\sffamily,
                                               inner sep=2pt] {$#1$}}
                                      }
                              }% end for tree
                  [,coordinate
                  [target\\ item,no edge
                      [recolection\\ certainity, EL=r
                          ["yes"]
                      ]
                      [recolection\\ uncertainity, EL=1-r,
                          [guess "yes", tier=L1, EL=g,
                              ["yes"]
                          ]
                          [guess "no", tier=L1, EL=1-g
                              ["no"]
                          ]
                      ]
                  ]
                  [,coordinate, no edge]
                  [target\\ item, no edge
                      [guess "yes", tier=L1, EL=g,
                              ["yes"]
                      ]
                      [guess "no", tier=L1, EL=1-g
                          ["no"]
                      ]
                   ]
                  ]
                      \end{forest} 
    \caption{Proposed multinomial processing tree of how people judge sentences in an agreement attraction task}
    \label{fig:mptModel}
\end{figure}

The aim of our second experiment was to test whether agreement attraction in Turkish may be an instance of a \textit{form-driven processing strategy}. Assuming that readers sometimes engage in shallow processing, they may end up with insufficient information to reliably classify a sentence as (un)acceptable. In such cases, participants may choose to classify sentences with plural-agreement-bearing verbs as acceptable if they have a memory of a nominal plural morpheme in the sentence. Such a response strategy would lead to a larger number of ‘acceptable’ responses in ungrammatical plural attractor conditions than in ungrammatical singular attractor conditions. 



\section{Experiment 2} \label{sec:exp2}

<<loadExperiment2Data>>=
fname_data2 <- "../workspace_exp2/exp_data.rds"
data_exp2 <- readRDS(file = fname_data2)
fname_form <- "../workspace_exp2/exp_form.rds"
form_exp2 <- readRDS(file = fname_form)
form_exp2 <- form_exp2[-c(56),]

# compute by-subject percentages of 'yes' responses, and average RTs 
avg_by_subj2 <- data_exp2 %>%
                group_by(subject, experiment, condition, 
                         grammatical, verb_num, attractor_num) %>%
                summarize(avRT = mean(RT), 
                          p_yes = mean(ResponseYes, na.rm = T), 
                          N = sum(!is.na(ResponseYes))  )

# reformat by-subject averages to a wide format
avg_by_subj_wide2 <- avg_by_subj2 %>% 
                      mutate(expcond = paste(experiment, condition, sep="_")) %>% 
                      ungroup() %>%
                      dplyr::select(-experiment, -condition, -avRT, -N,
                                    -grammatical, -verb_num, -attractor_num) %>%
                      tidyr::spread(expcond, p_yes) %>% 
                      mutate(delta_dc = AgrAttr_d - AgrAttr_c)

@

<<badSubjects2>>=
# identify participants 
bad_subjects2 <- subset(avg_by_subj_wide2, delta_dc <= 0.25 ) %>% .$subject

data_exp2_clean <- data_exp2 %>% subset(!subject %in% bad_subjects)

@

<<mergeData2>>=

df_merge_exp2 <- data_exp2_clean %>% ungroup() %>% 
                      dplyr::select(source=experiment, grammatical, attractor_num, # condition,
                                    subject, item=Item,
                                    ResponseYes, RT)
df_merge_exp2$experiment <- "Experiment 2"
df_merge_exp2$grammatical <- with(df_merge_exp2, ifelse(grammatical == "gram", 
                                                        "grammatical",
                                                        "ungrammatical"))
df_merge_exp2$attractor_num <- with(df_merge_exp2, ifelse(attractor_num == "pl", 
                                                          "plural", 
                                                          "singular"))
df_merge_exp2$item %<>% as.integer()
df_merge_exp2$subject %<>% as.character()

df_exp2_na_nofillers <- subset(df_merge_exp2, is.na(ResponseYes))

df_merged2 <- dplyr::bind_rows(df_merge_exp1, df_merge_exp2)
df_merged2$subject %<>% as.factor()
df_merged2$item %<>% as.factor()

df_exp2_na_nofillers <- subset(df_merged2, is.na(ResponseYes) & source != "filler")

df_merged2_nonna <- df_merged2 %>% subset(!is.na(ResponseYes))


@

In Experiment 2, we wanted to rule out the possibility of \textit{form-driven processing strategy}, namely participants deciding on the acceptability of a sentence using a memory of plural morpheme in the sentence when they do not have sufficient information to rate sentences (un)acceptable. 
 

\subsection{Participants} \label{sec:exp2:participants}

Eighty native speakers of Turkish in Experiment 1. The mean age is \Sexpr{mean(as.numeric(as.character(form_exp2$Age)))}, ranging from \Sexpr{min(as.numeric(as.character(form_exp2$Age)))} to \Sexpr{max(as.numeric(as.character(form_exp2$Age)))}. Across participants, a total \Sexpr{sum(is.na(df_exp2_na_nofillers$ResponseYes))} items were not responded to before the 5 second deadline by \Sexpr{length(unique(df_exp2_na_nofillers$subject))} different participants. These items were not included in the analysis. Experiments in this paper were carried out following the Declaration of Helsinki and the regulations concerning ethics in research in Bo\u{g}azi\c{c}i University. All participants provided informed consent. They were tested online, on IbexFarm, using their preferred platform, % Find citation for using IbexFarm and online testing etc?


\subsection{Materials} \label{sec:exp2:materials}

In Experiment 2, participants saw the sentences word by word in the middle of their screen. We have again formed 40 sets of items. The grammaticality of the sentences (\textit{grammatical} x \textit{ungrammatical}) and the number of the attractor (\textit{singular} x \textit{plural}) were manipulated. Unlike Experiment 1, we used nominalized relative clause attractors instead of nouns. We took advantage of syncretism between Turkish nominal and verbal plural marker. Both of these morphemes spells-out as \textit{-lAr}, which enables us to check whether agreement attraction in Turkish can be explained by an extremely shallow dependency parsing based on the forms of morphemes rather than linguistic features.

All experimental sentences followed the same template as the experiment one except for the nature of the attractor: \textit{RC-Bare Noun-Adverb-Verb}. 
We have used the same verbs, and have not changed the distribution of verb types. We also utilized the same or extremely similar adverbials in length. We again did not manipulate the number of the head noun and manipulated the number of the attractor. Relative clauses we used in this experiment are all object relative clauses and they are all marked with canonical \textit{-dIK} nominalizer. Since Turkish is a pro-drop language, we also dropped the subject within the embedded clause, thus ending up with a one-word object relative clause whose head is also the controller of the number agreement on the matrix verb. One example set of experimental items can be seen in \ref{item:exp2ExperimentalItems}.


\ex. \label{item:exp2ExperimentalItems}
\a. \textit{Plural Attractor, Ungrammatical Verb}\\ 
\gll *Tut-tuk-lar-ı aşcı mutfak-ta sürekli zıpl-ıyor-lar.\\ 
hire-\textsc{nmlz}-\textsc{pl}-\textsc{poss}  cook kitchen-\textsc{loc} non-stop  jump-\textsc{prog}-\textsc{pl}.\\
\glt `The cook that they hired were jumping in the kitchen non-stop.' 
\b. \textit{Singular Attractor, Ungrammatical Verb}\\ 
\gll *Tut-tuğ-u aşcı mutfak-ta sürekli zıpl-ıyor-lar.\\ 
hıre-\textsc{nmlz}-\textsc{poss}  cook kitchen-\textsc{loc} non-stop  jump-\textsc{prog}-\textsc{pl}.\\
\glt `The cook that they hired were jumping in the kitchen non-stop.'
\c. \textit{Plural Attractor, Grammatical Verb}\\ 
\gll Tut-tuk-lar-ı aşcı mutfak-ta sürekli zıpl-ıyor.\\ 
hire-\textsc{nmlz}-\textsc{pl}-\textsc{poss}  cook kitchen-\textsc{loc} non-stop  jump-\textsc{prog}.\\
\glt `The cook that they hired was jumping in the kitchen non-stop.'
\d. \textit{Singular Attractor, Grammatical Verb}\\ 
\gll Tut-tuğ-u aşcı mutfak-ta sürekli zıpl-ıyor.\\ 
hıre-\textsc{nmlz}-\textsc{poss}  cook kitchen-\textsc{loc} non-stop  jump-\textsc{prog}.\\
\glt `The cook that they hired was jumping in the kitchen non-stop.'

In our filler items for Experiment 2, we made sure that every sentence starts with an object relative clause. We used plural distractors with grammatical verbs and singular distractors with ungrammatical verbs. In all of our filler sentences, the dependency between the first NP subject and its verb resolved in an adverbial embedded sentence. Grammatical filler items in Experiment 2 all had a template of \textit{RC$_{\textsc{pl}}$-Bare Noun-Adverb-Converb-Noun-Adverb-Verb$_{\textsc{pl}}$}, whereas ungrammatical filler items used a template of \textit{RC$_{\Sg{}}$-Bare Noun-Adverb-Converb-Noun-Adverb-Verb$_{\Sg{}}$}

Again, to avoid a possible strategy where participants use plural ending as a direct indication of ungrammaticality, half of our fillers were with an overt plural marking on a grammatical verb while the other half were without an overt plural marking on an ungrammatical verb. We used Turkish pro-drop characteristics which enable participants to form a dependency between the matrix verb and the null subject. Example filler sentences can be seen in \ref{item:exp2FillerItems} 

\ex. \label{item:exp2FillerItems}
\a. \textit{Plural Grammatical Verb}\\ 
\gll Oku-t-tuk-lar-ı öğrenci başarılı ol-unca mutlu ol-du-lar.\\ 
read-\Caus{}-\textsc{nmlz}-\textsc{pl}-\textsc{poss}  student successful be-\textsc{nmlz} happy be-\textsc{pst}-\textsc{pl}.\\
\glt `When the student they sponsored become successful, they became happy.' 
\b. \textit{Singular Ungrammatical Verb}\\ 
\gll *Kandır-dığ-ı adam öde-me-yince bulaşık saatlerce yıka-dı.\\ 
trick-\textsc{nmlz}-\textsc{poss}  man pay-\Neg{}-\textsc{nmlz} dish for.hours clean-\textsc{pst}.\\
\glt Intended:`When the man he tricked did not pay, he cleaned dishes for hours.'


\subsection{Procedure and Analysis} \label{sec:exp2:procedure_analysis}



<<computeAverages2>>=

# avg_clean2 <- df_merged2 %>%
#                 group_by(experiment, source, grammatical, attractor_num) %>%
#                 summarize(avgRT = mean(RT), p_yes = mean(ResponseYes, na.rm = T))
# # XXX


avg_clean2 <- list()
avg_clean2$resp <- df_merged2_nonna %>% 
              plyr::ddply(c("experiment"), function(df) {
              df %>% se_cousineau(n_conditions = 4, subject, DV = ResponseYes, 
                           group = c("experiment", "source", "grammatical", "attractor_num"), 
                           is_proportion = TRUE)
})

avg_clean2$rt <- df_merged2_nonna %>%
              plyr::ddply(c("experiment"), function(df) {
              df %>% se_cousineau(n_conditions = 4, subject, DV = RT, 
                           group = c("experiment", "source", "grammatical", "attractor_num"), 
                           is_proportion = FALSE)
})

# TODO: Code ResponseCorrect and re-enable
# avg_clean$rt_correct <- df_merged2_nonna %>% subset(ResponseCorrect) %>%
#               plyr::ddply(c("experiment"), function(df) {
#               df %>% se_cousineau(n_conditions = 4, subject, DV = RT, 
#                            group = c("experiment", "source", "grammatical", "attractor_num"), 
#                            is_proportion = FALSE)
# })

avg_exp2 <- avg_clean2 %>% lapply(function(df) { df %>% subset(is.na(source) | source != "filler") })
#avg_fillers <- avg_clean %>% lapply(function(df) { df %>% subset(source == "filler") })


@

In Experiment 2, the same procedure as Experiment 1 has been followed with regards to how sentences are presented within the experiment. 

We analyzed the percentages of 'yes' answers given by the participants in experimental conditions. In the analysis of this experiment, we have included experimental items from our Experiments 1 and 2 to check the interaction between experiments and quantify the difference between verbal and nominal plural markers. In Experiment 2 as well, we excluded participants (\Sexpr{length(bad_subjects2)}) who had more than 0.25 points of difference in accuracy between grammatical conditions, which implicates that they did not give enough attention to all conditions. We used R packages brms \citep{R-brms_b} and rstan \citep{R-stan} to fit Bayesian hierarchical models \citep{GelmanHill:2007}. We added our independent variables, i.e. grammaticality of the sentence and the overt number information on the distractors, and random variable experiment as a factor. Analyses by items and participants are also conducted as a 
part of the Bayesian hierarchical models. Data regarding our experiments and analysis can be found in \texttt{link hidden due to blind review}.


% Should I rephrase these parts?
%Prior the experiments, participant gave information regarding themselves and a consent to start to the experiment. They read the instructions where we showed what they will see in the experiment, what will be going to ask to participants, and where we informed them to be fast and accurate during the experiment. Every session started with practice session where participants have been informed being a bit faster when they were not. The sentences were presented in the middle of the screen word-by-word on a web-based platform Ibex Farm (\url{http://spellout.net/ibexfarm/}). Each word stayed on the screen for 300 ms, unlike \citet{LagoEtAl:2018} and \citet{WagersEtAl:2009} where words stayed for 500 ms in the screen. After the sentence is completed, participants were asked "How did they find the sentence?" They were informed to press P on their keyboard for \textit{good} and Q for bad. Apart from the practice items, we did not provide any feedback regarding their answer. However, participants were asked to be faster when they waited more than 5000 ms to answer the acceptability question.

\subsection{Results} \label{sec:exp2:results}

\autoref{fig:exp2AvgResponse} shows the average proportions of 'acceptable' responses by experimental conditions for both Experiment 1 and Experiment 2. We see that there is no effect resembling agreement attraction in the ungrammatical conditions of Experiment 2. Ungrammatical conditions showed comparable effects (\Sexpr{avg_exp2$resp$M[7]} and \Sexpr{avg_exp2$resp$M[8]} for plural and singular attractors respeectively) regardless of the attractor's number.  



<<exp2AvgResponse, fig.cap='Estimates and 95\\% credible intervals for the regression coefficients for Experiment 1 and Experiment 2', fig.height=3, fig.align='center'>>=

avg_exp2 <- avg_clean2$resp %>% subset(is.na(source) | source != "filler") %>% subset(experiment == "Experiment 2")
avg_fillers2 <- avg_clean2$resp %>% subset(source == "filler") %>% subset(experiment == "Experiment 2")

p_avg_resp2 <- ggplot(avg_exp2, aes(grammatical, M, #linetype = attractor_num, 
                                    color = attractor_num, group = attractor_num)) + 
                geom_point(position = pd) + geom_line(position = pd) + 
                facet_wrap(~experiment) +
                theme_bw() + theme( strip.background = element_rect(fill="white") ) +
                xlab("") + ylab("Percentage 'acceptable'")

p_avg_resp2 <- p_avg_resp2 + geom_errorbar(aes(ymin = M - 1.96*SE, ymax = M + 1.96*SE), width = 0.1, position = pd)
p_avg_resp2 <- p_avg_resp2 + scale_y_continuous(labels=scales::percent, limits = c(0, 1))
p_avg_resp2 <- p_avg_resp2 + scale_color_discrete(name = "Attractor Number")

print(p_avg_resp2)


@

The observations we made through \autoref{fig:exp2AvgResponse} also surfaces when we look at the estimates and 95\% CIs of a Bayesian GLM in \autoref{fig:exp2ResponseModel}. As is visible from the figure, the model shows a negative three-way interaction between grammaticality, type of attractor (nominal vs. verbal), and attractor number, which entails a reduced effect of agreement attraction in Experiment 2 compared to Experiment 1. 

<<Model, include=FALSE>>=

# to-do: Rename 'cVerbalPlural' to 'cVerbalAttractor'
df_merged2 %<>% within(., {
  cGrammatical <- ifelse(grammatical == "grammatical", .5, -.5)
  cUngrammatical <- ifelse(grammatical == "ungrammatical", .5, -.5)
  cAttractorPlural <- ifelse(attractor_num == "plural", .5, -.5)
  cVerbalPlural <- ifelse(experiment == "Experiment 2", .5, -.5)
})
df_merged_nofillers2 <- df_merged2 %>% subset(is.na(source) | source != "filler")

# ## test model parameterization using a simple GLM first
# m <- glm(ResponseYes ~ cEndsInConsonant * cUngrammatical * cAttractorPlural,
#          data = df_merged_nofillers,
#          family = binomial("probit"))
# summary(m)

n_chains <- 4
n_cores <- 4
n_iter <- 2000

fname_exp2_responses <- "../workspace_exp2/model_responses"

library(brms)

m_responses2 <- brm(ResponseYes ~ cVerbalPlural * cUngrammatical * cAttractorPlural + 
                                 (cUngrammatical * cAttractorPlural + 1| subject) +
                                 (cUngrammatical * cAttractorPlural + 1| item),
                   data = df_merged_nofillers2,
                   family = bernoulli("probit"),
                   file = fname_exp2_responses, 
                   chains = n_chains, cores = n_cores, iter = n_iter)

@


<<exp2ResponseModel, fig.cap='Estimates and 95\\% credible intervals for the regression coefficients for Experiment 2', fig.height=3, fig.align='center'>>=

contrast_names2_le <- c("cUngrammatical" = "Ungrammaticality",
                    "cAttractorPlural" = "Plural Attactor",
                    "cVerbalPlural" = "Verbal Attractor",
                    "cUngrammatical:cAttractorPlural" = "Ungrammaticality * Plural Attractor",
                    "cVerbalPlural:cUngrammatical" = "Ungrammaticality * Verbal Attractor",
                    "cVerbalPlural:cAttractorPlural" = "Verbal Attractor * Plural Attractor",
                    "cVerbalPlural:cUngrammatical:cAttractorPlural" = "Verbal Attractor * Ungrammaticality * Plural Attractor")

    p_m_response_exp2 <- 
      create_model_coefs_plot( m_responses2, 
            plot_stats = T, map_names = contrast_names2_le,
            expand_right = 4.5, expand_top = 1.5, x_stat_adjust = .75,
            x_breaks = c(-3,-2,-1, 0, 1) ) + 
            xlab("Estimate (log-odds)")
    
    p_m_response_exp2 <- p_m_response_exp2 + annotate(x=-3, xend=1, y=0, yend=0, lwd=0.25, geom="segment")
print(p_m_response_exp2)


@


\subsection{Discussion} \label{sec:exp2:discussion}


In Experiment 2, we could not find any effect of agreement attraction in the acceptability ratings of ungrammatical conditions with a verbal plural attractor. However, number agreement attractions were observed when the attractors were nominal. Even though the forms of the two plural morphemes are the same form-wise, there is a distinct difference between the results of two experiments. One of the indications of zero-effect with verbal plural morpheme is that readers do not make decisions solely based on the form of the elements. This finding contradicts our hypothesized form-driven processing strategy and supports an account of agreement attraction based on the use of abstract linguistic features, rather than mere form.

However, results may be more telling with regards to the other theories of agreement attraction. These results seem unexpected within the cue-based retrieval mechanisms. Even though the root of the attractor is verbal, the morpheme is the same with the third person plural possessive marker since the relative clauses in Turkish are always nominalized and the subject is marked with the genitive case. The findings of this experiment indicate towards more fine-grained features needs to be utilized. One other possible explanation within the cue-based retrieval models can be formed around the status of agreement markers. One can say that the agreement process is completed in the verbal \textit{-lAr}; in other words, it is not the triggering morpheme but the probe of the agreement. This difference would mean that verbal \textit{-lAr} should not start any search for dependency resolution. In contrast to verbal \textit{-lAr}, the plural morpheme on the genitive is supposed to be triggering part of the agreement, not the probe. However, in Turkish embedded clauses, where genitive subjects can be seen, the number agreement works differently than the matrix level agreement. When the genitive subject of an embedded clause is marked with plural it is ungrammatical to have plural marking on the verb. 
This prohibition in return means that the genitive subjects should not create an expectation for a plural marked verb, which was believed to be the reason for the agreement attraction in \citet{LagoEtAl:2018}.


As for the marking and morphing theories, the results of Experiment 2 are completely expected and mitigated by the syntactic depth effects. Due to the genitive possessor's limited inner complexity compared to that of relative clause modifiers, marking and morphing theories would expect higher contribution from the genitive attractors to the final representation of number information. 


\section{General Discussion} \label{sec:general_discussion}



\bibliography{library,new-references}

\end{document}

%
% Please see the package documentation for more information
% on the APA6 document class:
%
% http://www.ctan.org/pkg/apa6
%