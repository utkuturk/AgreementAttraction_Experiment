\documentclass[doc,a4paper,man,natbib,floatsintext,noextraspace]{apa6}
<<echo=F>>=
# Set the global chunk options
set.seed(42)
knitr::opts_chunk$set(encoding = 'UTF-8',
                      cache.extra = knitr::rand_seed,
                      echo = F,
                      results = 'hide',
                      message = F,
                      warning = F)
options("citation_format" = "pandoc")
@

<<setup, echo=FALSE, cache=FALSE>>=
## numbers >= 10^5 will be denoted in scientific notation,
## and rounded to 2 digits
options(scipen = 1, digits = 2)
@

\usepackage[english]{babel}
\usepackage[utf8x]{inputenc}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{graphicx}
\usepackage[colorinlistoftodos]{todonotes}
\usepackage[singlespacing]{setspace}

<<>>=

# load packages
library(patchSynctex)
library(knitcitations)
library(car, warn.conflicts = FALSE)
library(MASS)
library(brms)
library(xtable)
library(ggpubr)
library(languageR)
library(tidyverse)
library(gdata)
library(magrittr)
library(ggplot2)
theme_set(theme_bw())

# to-do: check that the CI-computation code is up-to-date
source("../scripts/misc.R")

@
\title{The Role of Shallow Processing in Agreement Attraction}
\shorttitle{Your APA6-Style Manuscript}
\author{Utku Türk, Pavel Loga\v{c}ev}
\affiliation{Boğaziçi University}


\abstract{We report the results of two speeded acceptability judgment experiments in Turkish. We hypothesized an alternative explanation for agreement attraction effects in Turkish that is based on shallow processing. Our findings contradict our hypothesized form-driven processing strategy and support an account of agreement attraction based on the use of abstract linguistic features, rather than mere form.}

\input{settings.tex}

\begin{document}

\maketitle


\section{Introduction} \label{sec:Intro}

% %\footnote{\printglossaries}. % add this to somewhere in the first page I suppose
% 
% \subsection{Agreement Attraction Thingy} \label{sec:Intro:literature}
% 
% \subsubsection{Morphophonology} \label{sec:Intro:literature:morphophonology}
% 
% %fill here accordingly to your results AFTER YOU WRITE THE RESULT.
% 
% 
% \subsubsection{related sub-sub-field studies} \label{sec:Intro:literature:others}
% 
% \subsubsection{This work details} \label{sec:Intro:literature:thiswork}

% \citet{LagoEtAl:2018} hypothesize that genitive NPs can trigger agreement attraction in Turkish, because Turkish makes heavy use of genitive subjects, which means genitives are a priori likely to function as agreement controllers. The underlying assumption is that agreement processes rely on, at least partially, the case of an NP to determine its fit for the role of an agreement controller. 
% If that is so, their items are problematic %as in ... give an example
% in that the marking on the head noun is ambiguous between possessive and accusative case, while only possessive-marked NPs qualify as agreement controllers. Therefore, if engaged in shallow processing, readers may be more likely to misidentify the genitive NP as the agreement controller when the head noun, which is the only other alternative, is ambiguous, compared to when it is not.

% In Experiment 1, we decided to test this hypothesis 


% to-do: This all needs to go up, to the description of the potential confound in Lago et al.'s study.
%This change was due to the morpho-phonologic nature of possessive suffix in Turkish, which spell-outs as (\textit{-I}) after a consonant same as the accusative. 


\section{Experiment 1} \label{sec:exp1}

% do not do this in one chunk. differentiate the chunks and give them proper names.
<<>>=

fname_data <- "../workspace_exp1/exp_data.rds"
data_exp1 <- readRDS(fname_data)
fname_form <- "../workspace_exp1/exp_form.rds"
form_exp1 <- readRDS(file = fname_form)

### note: the low accuracy on fillers is not caused by a couple of items
###       -> see below
# filler_avgs <- 
# data_exp1 %>% subset(Type == "filler") %>% group_by(Item, condition) %>% 
#               summarize(M = mean(ResponseYes, na.rm = T)) %>%
#               arrange(condition, Item)
# fillers %>% subset(condition == "a") 
# fillers %>% subset(condition == "b")
###

# compute by-subject percentages of 'yes' responses, and average RTs 
avg_by_subj <- data_exp1 %>%
                group_by(subject, experiment, condition, 
                         grammatical, verb_num, attractor_num) %>%
                summarize(avRT = mean(RT), 
                          p_yes = mean(ResponseYes, na.rm = T), 
                          N = sum(!is.na(ResponseYes))  )

# reformat by-subject averages to a wide format
avg_by_subj_wide <- avg_by_subj %>% 
                      mutate(expcond = paste(experiment, condition, sep="_")) %>% 
                      ungroup() %>%
                      dplyr::select(-experiment, -condition, -avRT, -N,
                                    -grammatical, -verb_num, -attractor_num) %>%
                      tidyr::spread(expcond, p_yes) %>% 
                      mutate(delta_dc = AgrAttr_d - AgrAttr_c)

# Load Lago et al.'s monolingual data
fname_lagoetal <- "../Data/Lago_et_al/Lago_data.csv"
df_lagoetal <- read.csv(fname_lagoetal, encoding = "UTF-8", as.is = T)
df_lagoetal %<>% subset(Group == "monolingual")
df_lagoetal %<>% dplyr::select(-Accuracy, -L1:-Group, -List:-SelfRateGerman)

# Note: All rows with Experiment == "offline" also seem to be for 
#       the UNP task ('Grammatical' is NA). I wonder if these were
#       the same subjects, or if the subject labels were simply the same
#       for the two experiments.
with(df_lagoetal, stopifnot( is.na(Grammatical) == (Experiment == "offline") ))

df_lagoetal_unp <- df_lagoetal %>% 
                    subset(is.na(Grammatical)) %>%
                    dplyr::select(-Grammatical:-Label)
df_lagoetal_attr <- df_lagoetal %>% 
                  subset(!is.na(Grammatical)) %>%
                  dplyr::select(-Distance:-NewCond)

df_lagoetal_attr %<>% mutate(ResponseYes = (Response == "yes") ) %>% 
                      dplyr::select(-Response)
df_lagoetal_attr %<>% ungroup() %>%
                      dplyr::select(grammatical=Grammatical,
                                    attractor_num=Attractor,
                                    experiment=Experiment,
                                    lagoetal_condition=Condition, 
                                    subject=Participant, 
                                    item=Item,
                                    ResponseYes,
                                    RT)

# map to our condition labels
lagoetal_condition_mapping <- data.frame( condition = c("a", "b", "c", "d"),
                                          lagoetal_condition = c("d", "b", "c", "a"), 
                                          stringsAsFactors = F)
df_lagoetal_attr %<>% left_join( lagoetal_condition_mapping, by = "lagoetal_condition" )

# compute by-subject percentages of 'yes' responses, and average RTs 
avg_by_subj_lagoetal <- df_lagoetal_attr %>%
                            group_by(subject, experiment, condition, grammatical, attractor_num) %>%
                            summarize(avRT = mean(RT), 
                                      p_yes = mean(ResponseYes, na.rm = T), 
                                      N = sum(!is.na(ResponseYes))  )

# reformat by-subject averages to a wide format
avg_by_subj_lagoetal_wide <- avg_by_subj_lagoetal %>% 
                                    mutate(expcond = paste(experiment, condition, sep="_")) %>% 
                                    ungroup() %>%
                                    dplyr::select(-experiment, -condition, -avRT, -N,
                                                  -grammatical, -attractor_num) %>%
                                    tidyr::spread(expcond, p_yes) %>% 
                                    mutate(delta_dc = online_d - online_c)


# identify bad participants 
bad_subjects <- subset(avg_by_subj_wide, delta_dc <= 0.25 ) %>% .$subject
data_exp1_clean <- data_exp1 %>% subset(!subject %in% bad_subjects)

# identify bad participants 
bad_subjects_lagoetal <- subset(avg_by_subj_lagoetal_wide, delta_dc <= 0.25 ) %>% .$subject
df_lagoetal_attr_clean <- df_lagoetal_attr %>% subset(!subject %in% bad_subjects_lagoetal)

# merge both datasets
df_merge_exp1 <- data_exp1_clean %>% ungroup() %>% 
                      dplyr::select(source=experiment, 
                                    grammatical, 
                                    attractor_num,
                                    # condition,
                                    subject, 
                                    item=Item,
                                    ResponseYes, 
                                    RT)
df_merge_exp1$experiment <- "Experiment 1"
df_merge_exp1$grammatical %<>% dplyr::recode(gram="grammatical", ungram="ungrammatical")
df_merge_exp1$attractor_num %<>% dplyr::recode(pl="plural", sg="singular")

df_merge_exp1$item %<>% as.integer()
df_merge_exp1$subject %<>% as.character()



df_merge_lago <- df_lagoetal_attr_clean %>%
                      ungroup() %>% 
                      dplyr::select(grammatical, attractor_num,
                                    subject, item, ResponseYes, RT)
df_merge_lago$experiment <- "Lago et al. (2018)" 
df_merge_lago$source <- NA




word_freq <- readxl::read_excel("../Data/frequencies_exp1_and_lago.xlsx", sheet = 1)
word_freq$freq_percentage %<>% as.numeric()
word_freq %<>% dplyr::select(-freq_standardized, -freq_percentage, -word)
word_freq %<>% tidyr::spread(place, freq_count)

word_freq %<>% dplyr::group_by(exp) %>% 
               dplyr::mutate( freq_cat_n1 = ifelse(n1 > median(n1), "high", "low"),
                              freq_cat_n2 = ifelse(n2 > median(n2), "high", "low"),
                              freqlog_n1 = scale(log(n1)),
                              freqlog_n2 = scale(log(n2)),
                              freqlog_n1n2 = log(n1) - log(n2)
                            ) %>% 
                ungroup()
# word_freq$freq_cat_n1 %<>% as.factor()
# word_freq$freq_cat_n2 %<>% as.factor()


word_freq_exp1 <- word_freq %>% subset(exp == "exp1") %>% dplyr::select(-exp)
df_merge_exp1 %<>% left_join(word_freq_exp1, by = "item")

word_freq_lago <- word_freq %>% subset(exp == "lagoetal") %>% dplyr::select(-exp)
df_merge_lago %<>% left_join(word_freq_lago, by = "item")
df_merge_lago$item %<>% add(1000)

df_merged <- dplyr::bind_rows(df_merge_exp1, df_merge_lago)
df_merged$subject %<>% as.factor()
df_merged$item %<>% as.factor()

df_exp1_na_nofillers <- subset(df_merge_exp1, is.na(ResponseYes) & source != "filler")
df_merged %<>% subset( !is.na(ResponseYes) )

@

In Experiment 1, we tested whether speakers of Turkish make fewer agreement attraction errors when the local ambiguity in the head noun is resolved. 
Specifically, we tried to replicate \citet{LagoEtAl:2018} study. However, instead of using morphologically ambiguous head nouns, we uses nouns ending in a vowel, thus resolving the ambiguity between the accusative and possessive. 

\subsection{Participants} \label{sec:exp1:participants}

We recruited 118 undergraduate students to participate in Experiment 1 in exchange for course credit. All participants were native speakers of Turkish, with an average age of \Sexpr{round(mean(form_exp1$Age))} (range: \Sexpr{min(form_exp1$Age)} -- \Sexpr{max(form_exp1$Age)}).  
Experiment were carried out following the Declaration of Helsinki and the regulations concerning ethics at research in Bo\u{g}azi\c{c}i University. All participants provided informed consent prior to their participation.

\subsection{Materials} \label{sec:exp1:materials}

We used 40 sets of sentences like (\ref{item:exp1ExperimentalItems}), in which we manipulated 
(i) the number of the attractor noun, and
(ii) the number agreement on the verb. 
Plural number and plural agreement were both marked with the affix \textit{-ler/-lar}, while singular number and singular agreement were marked with its absence. 
%
We have used the experimental items in \citet{LagoEtAl:2018} as a base. 
All sentences started with a complex subject NP like \textit{`the manager's cook'} (\textit{yöneticinin aşcısı}), in which the possessor, which functioned as the attractor, carried genitive case, and the head noun carried possessive case. 
Because the head noun was singular in all conditions, sentences with plural verb agreement were ungrammatical. 
Moreover, as in the original study, the properties of the nouns in the complex subject NP and the relation between these nouns held constant in our replication. 
The distribution of the verb types followed the same pattern as in \citet{LagoEtAl:2018}, namely twenty unergatives, eighteen unaccusatives, and two optionally transitive verbs. 
Both in \citet{LagoEtAl:2018} and in our replication, pre-verbal adverbials consisting of 2-3 words (15 characters on average) are used.
Unlike the \citet{LagoEtAl:2018} sentences, our head nouns were vowel-ending, and therefore not ambiguous between accusative case, for which the case suffix is \textit{-yI}, and possessive case, for which the suffix is \textit{-sI}. 


\ex. \label{item:exp1ExperimentalItems}
%
\a. \textsc{Plural Attractor, Ungrammatical (Plural Verb)} \label{item:exp1expitem-plpl}\\ 
  \gll *[Yönetici-ler-in \textbf{aşcı-sı}] mutfak-ta sürekli \textbf{zıpla-dı-lar}.\\ 
  manager-\textsc{pl}-\textsc{gen}  cook-\textsc{poss} kitchen-\textsc{loc} non-stop  jump-\textsc{pst}-\textsc{pl}.\\
  \glt \textit{`The cooks of the manager were jumping in the kitchen non-stop.'}
%
\b. \textsc{Plural Attractor, Grammatical (Singular Verb)} \label{item:exp1expitem-plsg}\\ 
  \gll [Yönetici-ler-in \textbf{aşcı-sı}] mutfak-ta sürekli \textbf{zıpla-dı}.\\ 
  manager-\textsc{pl}-\textsc{gen}  cook-\textsc{poss} kitchen-\textsc{loc} non-stop  jump-\textsc{pst}.\\
  \glt \textit{`The cooks of the manager was jumping in the kitchen non-stop.'}
%
\c. \textsc{Singular Attractor, Ungrammatical (Plural Verb)} \label{item:exp1expitem-sgpl}\\ 
  \gll *[Yönetici-nin \textbf{aşcı-sı}] mutfak-ta sürekli \textbf{zıpla-dı-lar}.\\ 
  manager-\textsc{gen}  cook-\textsc{poss} kitchen-\textsc{loc} non-stop  jump-\textsc{pst}-\textsc{pl}.\\
  \glt \textit{`The cook of the manager were jumping in the kitchen non-stop.'}
%
\d. \textsc{Singular Attractor, Grammatical (Singular Verb)}\label{item:exp1expitem-sgsg}\\ 
  \gll [Yönetici-nin \textbf{aşcı-sı}] mutfak-ta sürekli \textbf{zıpla-dı}. \\ 
  manager-\textsc{gen}  cook-\textsc{poss} kitchen-\textsc{loc} non-stop  jump-\textsc{pst}.\\
  \glt \textit{`The cook of the manager was jumping in the kitchen non-stop.'}

We intermixed our experimental sentences with 40 filler sentences of two types, as illustrated in (\ref{item:exp1FillerItems}). 
To compensate for the fact that among experimental sentences, all ungrammatical sentences ended in a plural-agreeing verb, while all grammatical sentences ended in a singular-agreeing verb, we included 20 grammatical sentences with plural verbs, and 20 ungrammatical sentences with singular agreement. 
This was done in order to discourage participants from using a strategy based on verb number. 
Filler items followed a similar template in which sentence again started with a complex genitive-possessive noun phrase. 
However, in filler items, they were the controller of an embedded clause which serves as a adverbial. 
In grammatical fillers, we have made use of pro-dropped subject strategy in Turkish; thus, it enabled us to use plural verb without having ungrammatical sentences as in (\ref{item:exp1GrammaticalFiller}). The object \textit{tutarsızlık} is a bare nominal preceding a light verb construction. 
Differently in ungrammatical fillers, bare nominal did not precede a light verb construction, but an adverb and a verb. Since Turkish only allows bare nominals right next to the verb, sentences were deemed ungrammatical when the participants read the verb. 

%Even though filler items did not follow a strict template as the experimental items, they were created within a template of \textit{Noun$_{{\textsc{gen}}}$-Noun$_{{\textsc{gen}}}$-Converb-Noun-Adverb-Verb}. The ungrammaticality was created non-locally in the filler items to avoid task strategies. Example filler sentences can be seen in \ref{item:exp1FillerItems}.


\ex. \label{item:exp1FillerItems}
%
\a. \label{item:exp1GrammaticalFiller} \textsc{Grammatical Filler (Plural Verb)}\\ 
  \gll [Sosyolog-un \textbf{öğrenci-si}] konuş-unca tutarsızlık açığ-a \textbf{çıkar-dı-lar}.\\ %utku: what does this bold mean? if it the dependency between them then the bold parts are not correct. ogrencisi is the subject of the verb konusunca, and the subject of the matrix verb cikardilar is omitted.
  sociolog-\textsc{gen}  student-\textsc{poss} speak-\textsc{nmlz} inconsistency  open-\textsc{dat} deduct-\textsc{pst}-\textsc{pl}.\\
  \glt \textit{`When the student of the sociologist spoke, they revealed an inconsistency.'}
%to-do: Translation above doesn't make sense.
%
%
\b. \textsc{Ungrammatical Filler (Singular Verb)}\\ 
\gll *[Dansöz-ün \textbf{koca-sı}] var-ınca kapı sakince \textbf{aç-tı}.\\ 
dancer-\textsc{gen}  husband-\textsc{poss} arrive-\textsc{nmlz} door slowly  open-\textsc{pst}.\\
\glt \textit{Intended:`When the husband of the dancer came, the door opened slowly.'}
% to-do: Does the above mean that it's grammatical with another meaning?

\subsection{Procedure} \label{sec:exp1:procedure}

The experiment was run online, using the web-based platform Ibex Farm (\url{http://spellout.net/ibexfarm/}). Each experimental session took approximately 25 minutes to complete.
%
Prior to the start of the experiment, participants provided demographic information, as well as informed consent to participate in the experiment. They read the instructions, and were given 9 practice trials before the experiment began.
%
Each trial began with a blank screen for 600 ms, followed by a word-by-word RSVP presentation of the sentence in the center of the screen, followed by an acceptability judgment. 
Sentences were presented word-by-word in 30pt font size, and at a rate of 400 ms per word. Between each word, participants saw a blank screen for 100 ms. Participants pressed the key 'P' for \textit{'acceptable'} and 'Q' for \textit{'unacceptable'}. They were instructed to provide an acceptability rating before the 5,000 ms deadline. During the experiment, they were reminded to respond faster if they responded too slowly. 

Participants saw 40 experimental and 40 filler sentences. Experimental sentences were distributed among four different lists according to a Latin-square design. Every participant saw one version of the experiment with a specific list and one item per condition.   

\subsection{Analysis} \label{sec:exp1:analysis}

Since our aim was to test whether the morphological ambiguity present in the \citet{LagoEtAl:2018} items affected the presence or magnitude of the agreement attraction effect, statistically, we needed to test for the presence of an interaction between 
(i) the presence of the morphological ambiguity on the head noun, and 
(ii) the agreement attraction effect. 
In order to do so, we decided to analyze the data from the present experiment together with Lago et al.'s data, using experiment as an additional factor in the analysis.

%All experimental trials from both experiments (Experiment 1 and  Lago et al.'s study) was included in the analysis. 

Prior to analysis we removed the data for all participants who failed to show sufficient sentitivity to the effect of grammaticality in singular attractor conditions, i.e., when no agreement attraction was expected. Specifically, we removed all participants for whom the difference in the percentage of `yes' responses between the grammatical condition \ref{item:exp1expitem-sgsg} and the ungrammatical condition \ref{item:exp1expitem-sgpl} was below the threshold of 25 percentage points. As a result, we excluded \Sexpr{length(bad_subjects)} participants from experiment 1, and \Sexpr{stopifnot(length(bad_subjects_lagoetal) == 1)} one participant from the Lago et al. data

We used the R packages brms \citep{R-brms_b} and rstan \citep{R-stan} to fit Bayesian hierarchical models \citep[e.g.,][]{GelmanHill:2007}. We analyzed only experimental sentences, and used 
(i) grammaticality of the sentence, 
(ii) attractor number, and 
(iii) presence of morphological ambiguity (i.e., experiment), as well as all their interactions as predictors. 
Moreover, we used by-participant and by-item intercepts and slopes for all predictors.
Data for experiment 1, along with our analysis scripts can be found in \url{https://github.com/utkuturk/replication_lagoetal2018}.


\subsection{Results} \label{sec:exp1:results}

<<>>=

df_merged %<>% mutate(ResponseCorrect = (ResponseYes == (grammatical == "grammatical") ) )
df_merged_nonna <- df_merged %>% subset(!is.na(ResponseYes))

# avg_clean <- 
# df_merged %>% subset(experiment == "Lago et al. (2018)") %>%
#      group_by(experiment, source, grammatical, attractor_num, subject) %>%
#      summarize(p_yes = mean(ResponseYes, na.rm=T)) %>%
#      summarize(p_yes = mean(p_yes))

avg_clean <- list()
avg_clean$resp <- df_merged_nonna %>% 
              plyr::ddply(c("experiment"), function(df) {
              df %>% se_cousineau(n_conditions = 4, subject, DV = ResponseYes, 
                           group = c("experiment", "source", "grammatical", "attractor_num"), 
                           is_proportion = TRUE)
})

avg_clean$rt <- df_merged_nonna %>%
              plyr::ddply(c("experiment"), function(df) {
              df %>% se_cousineau(n_conditions = 4, subject, DV = RT, 
                           group = c("experiment", "source", "grammatical", "attractor_num"), 
                           is_proportion = FALSE)
})

avg_clean$rt_correct <- df_merged_nonna %>% subset(ResponseCorrect) %>%
              plyr::ddply(c("experiment"), function(df) {
              df %>% se_cousineau(n_conditions = 4, subject, DV = RT, 
                           group = c("experiment", "source", "grammatical", "attractor_num"), 
                           is_proportion = FALSE)
})

avg_exp <- avg_clean %>% lapply(function(df) { df %>% subset(is.na(source) | source != "filler") })
avg_fillers <- avg_clean %>% lapply(function(df) { df %>% subset(source == "filler") })


pd <- position_dodge(0.0)
p_avg_resp <- avg_exp$resp %>%
              ggplot(aes(grammatical, M, #linetype = attractor_num, 
                         color = attractor_num, group = attractor_num)) + 
                geom_point(position = pd) + geom_line(position = pd) + 
                facet_wrap(~experiment)

p_avg_resp <- p_avg_resp + geom_errorbar(aes(ymin = M - 1.96*SE, ymax = M + 1.96*SE), width = 0.1, position = pd)

# p_avg_resp <- p_avg_resp + geom_line(data = avg_fillers) + 
#                             geom_point(data = avg_fillers) + 

p_avg_resp <- p_avg_resp + theme( strip.background = element_rect(fill="white") ) +
                           theme_bw() + xlab("") + ylab("Percentage 'acceptable'")
p_avg_resp <- p_avg_resp + scale_y_continuous(labels=scales::percent)#, breaks = c(0, .25, .5, .75, 1))
p_avg_resp <- p_avg_resp + theme_bw()
p_avg_resp <- p_avg_resp + scale_color_discrete(name = "Attractor Number")

@


<<>>=
avg_exp_resp_exp1 <- avg_exp$resp %>% subset(experiment == "Experiment 1")
avg_exp_resp_lagoetal <- avg_exp$resp %>% subset(experiment == "Lago et al. (2018)")

@

\autoref{fig:exp1AvgResponse} shows the average proportions of ‘acceptable’ responses by experimental condition for both the original experiment in \citet{LagoEtAl:2018} and our replication with unambiguous possessive marking. 
\Sexpr{ 
cur_entry1 = avg_exp$resp %>% filter(experiment == "Experiment 1", grammatical == "ungrammatical", attractor_num == "plural");
cur_entry2 = avg_exp$resp %>% filter(experiment == "Experiment 1", grammatical == "ungrammatical", attractor_num == "singular") }%
It shows that ungrammatical sentences with plural attractors are rated as acceptable more often
(M = \Sexpr{cur_entry1$M}, 
SE = \Sexpr{cur_entry1$SE}) 
than their counterparts with singular attractors 
(M=\Sexpr{cur_entry2$M}, 
SE=\Sexpr{cur_entry2$SE}).
%
\Sexpr{ 
cur_entry1lago = avg_exp$resp %>% filter(experiment == "Lago et al. (2018)", grammatical == "ungrammatical", attractor_num == "plural");
cur_entry2lago = avg_exp$resp %>% filter(experiment == "Lago et al. (2018)", grammatical == "ungrammatical", attractor_num == "singular") }%
%This means that ungrammatical sentences with plural attractors were classified as acceptable more often than their counterparts with singular attractors. 
The magnitude of the effect (\Sexpr{sprintf("%0.2f", cur_entry1$M-cur_entry2$M)}) was in line with the findings reported in \citet{LagoEtAl:2018}, where the difference was \Sexpr{sprintf("%0.2f", cur_entry1lago$M-cur_entry2lago$M)}.
% 
Accuracy rates for grammatical conditions were nearly equal
\Sexpr{ 
cur_entry3 = avg_exp$resp %>% filter(experiment == "Experiment 1", grammatical == "grammatical", attractor_num == "singular");
cur_entry4 = avg_exp$resp %>% filter(experiment == "Experiment 1", grammatical == "grammatical", attractor_num == "plural"); }%
(M = \Sexpr{cur_entry3$M} and \Sexpr{cur_entry4$M}, SE = \Sexpr{cur_entry3$SE} and \Sexpr{cur_entry4$SE}, for singular and plural attractors respectively). 


<<exp1AvgResponse, fig.cap='Average percentages of `acceptable\' responses in Experiment 1 and \\citet{LagoEtAl:2018}. Within-subject 95\\% confidence intervals in brackets \\cite{Cousineau:2005,Morey:2008}.', fig.height=3, fig.align='center'>>=
print(p_avg_resp)

@

<<exp1models, include=FALSE>>=

df_merged %<>% within(., {
  cGrammatical <- ifelse(grammatical == "grammatical", .5, -.5)
  cUngrammatical <- ifelse(grammatical == "ungrammatical", .5, -.5)
  cAttractorPlural <- ifelse(attractor_num == "plural", .5, -.5)
  cEndsInConsonant <- ifelse(experiment != "Experiment 1", .5, -.5)
  #cFreqlog_n1n2 <- scale(freqlog_n1n2)
  #cFreqlog_n1 <- scale(freqlog_n1)
  #cFreqlog_n2 <- scale(freqlog_n2)
})
df_merged_nofillers <- df_merged %>% subset(is.na(source) | source != "filler")

# ## test model parameterization using a simple GLM first
# m <- glm(ResponseYes ~ (cFreqlog_n1 + cFreqlog_n2) *
#            cEndsInConsonant * cUngrammatical * cAttractorPlural,
#          data = df_merged_nofillers,
#          family = binomial("probit"))
# summary(m)

n_chains <- 4
n_cores <- 4
n_iter <- 2000

fname_exp1_responses <- "../workspace_exp1/fit_responses"
m_responses <- brm(ResponseYes ~ cEndsInConsonant * cUngrammatical * cAttractorPlural + 
                                 (cUngrammatical * cAttractorPlural + 1| subject) + 
                                 (cUngrammatical * cAttractorPlural + 1| item),
                   data = df_merged_nofillers,
                   family = bernoulli("probit"), 
                   chains = n_chains, cores = n_cores, iter = n_iter,
                   file = fname_exp1_responses)

fname_exp1_responses_exp1only <- "../workspace_exp1/fit_responses_exp1only"
m_responses_exp1only <- brm(ResponseYes ~ cUngrammatical * cAttractorPlural * freqlog_n1n2 + 
                                 (cUngrammatical * cAttractorPlural * freqlog_n1n2 + 1| subject) + 
                                 (cUngrammatical * cAttractorPlural + 1| item),
                   data = df_merged_nofillers %>% subset(experiment == "Experiment 1"),
                   family = bernoulli("probit"), 
                   chains = n_chains, cores = n_cores, iter = n_iter, init_r = .1,
                   file = fname_exp1_responses_exp1only
                   )

fname_exp1_responses_Lagoonly <- "../workspace_exp1/fit_responses_lagoonly"
m_responses_Lagoonly <- brm(ResponseYes ~ cUngrammatical * cAttractorPlural * freqlog_n1n2 + 
                                 (cUngrammatical * cAttractorPlural * freqlog_n1n2 + 1| subject) + 
                                 (cUngrammatical * cAttractorPlural + 1| item),
                   data = df_merged_nofillers %>% subset(experiment != "Experiment 1"),
                   family = bernoulli("probit"), 
                   chains = n_chains, cores = n_cores, iter = n_iter, init_r = .1,
                   file = fname_exp1_responses_Lagoonly)

fname_exp1_rts <- "../workspace_exp1/fit_responses_rt"
m_rts <- brm(RT ~ cEndsInConsonant * cUngrammatical * cAttractorPlural * freqlog_n1n2 +
                                 (cUngrammatical * cAttractorPlural * freqlog_n1n2 + 1| subject) +
                                 (cUngrammatical * cAttractorPlural + 1| item),
                   data = df_merged_nofillers,
                   family = lognormal(),
                   chains = n_chains, cores = n_cores, iter = n_iter,
                   file = fname_exp1_rts)

 model_results_table <- fixef(m_responses, summary = T, robust = F) %>% 
  as.data.frame() #%>% tibble::rownames_to_column("variables")

@

A Bayesian GLM assuming a Bernoulli distribution with a probit-link function was fit to participants' `acceptable' responses. The model's estimates and 95\% credible intervals are shown in \autoref{fig:exp1ResponseModel}. 
%
%They confirm the observations we stated above: the positive interaction between sentence grammaticality and attractor number is in line with a larger effect of attractor number in ungrammatical sentences. 
%
The main effect of \textit{ungrammaticality} (\Sexpr{print_estimate_with_ci( m_responses, 'cUngrammatical' )}) indicates that, on average, participants were quite good at distinguishing between grammatical and ungrammatical sentences. Meanwhile, the positive interaction between \textit{ungrammaticality} and \textit{attractor number} (\Sexpr{print_estimate_with_ci( m_responses, 'cUngrammatical:cAttractorPlural')}) indicated a larger effect of attractor number in ungrammatical conditions, and thus a number agreement attraction effect.
Importantly, there was no evidence for a three-way interaction between \textit{the presence of ambiguity}, \textit{ungrammaticality} and \textit{attractor number} (\Sexpr{print_estimate_with_ci( m_responses, 'cEndsInConsonant:cUngrammatical:cAttractorPlural')}).

% to-do:
% Importantly, even if there was an interaction with experiment, it's relatively small, so it wouldn't reduce the other interaction to 0. 

%Moreover, this findings are also predicted by cue-based retrieval models \citep{engelmann2019effect, vasishth2019computational} and last rendition of marking and morphing theory by \citet{HammerlyEtAl:2019}. %does it tho? especially with regards to what sol lago says: gen and morphophonology gives clues. maybe we should take a look at speeded acceptability? 
%maybe this is not the perfect place to write this.


<<exp1ResponseModel, fig.cap='Estimates and 95\\% credible intervals for the regression coefficients for the model of Experiment 1 and Lago et al. (2018).', fig.height=3, fig.align='center'>>=
contrast_names <- c("cUngrammatical" = "Ungrammaticality",
                    "cAttractorPlural" = "Plural Attactor",
                    "cUngrammatical:cAttractorPlural" = "Ungrammaticality * Plural Attractor",
                    "cEndsInConsonant" = "Ambiguity",
                    "cEndsInConsonant:cUngrammatical" = "Ambiguity * Ungrammaticality",
                    "cEndsInConsonant:cAttractorPlural" = "Ambiguity * Plural Attractor",
                    "cEndsInConsonant:cUngrammatical:cAttractorPlural" = "Ambiguity * Ungrammaticality * Plural Attractor")

p_m_response <- 
  create_model_coefs_plot( m_responses, 
        plot_stats = T, map_names = contrast_names,
        expand_right = 2.5, expand_top = 2, x_stat_adjust = 1.1,
        x_breaks = c(-3,-2,-1, 0,1, 2) ) + 
        xlab("Estimate (probit)")

suppressWarnings({
print(p_m_response + annotate(x=-3, xend=2, y=0, yend=0, lwd=0.25, geom="segment") + facet_wrap(~"Experiment 1 and Lago et al. (2018)"))
})

@


<<exp1ResponseModelSepExp1AndLago, fig.cap='Estimates and 95\\% credible intervals for the regression coefficients for Experiment1 and Lago et al. (2018).', fig.height=5, fig.align='center'>>=

contrast_names_exp1 <- c("cUngrammatical" = "Ungrammaticality",
                         "cAttractorPlural" = "Plural Attactor",
                         "freqlog_n1n2"="log Frequency: N1-N2",
                         "cUngrammatical:freqlog_n1n2" = "Ungrammaticality * log Frequency: N1-N2",
                         "cAttractorPlural:freqlog_n1n2" = "Plural Attactor * log Frequency: N1-N2",
                         "cUngrammatical:cAttractorPlural" = "Ungrammaticality * Plural Attractor",
                         "cUngrammatical:cAttractorPlural:freqlog_n1n2" = "Ungrammaticality * Plural Attractor * log Frequency: N1-N2"
                        )

p_m_response_exp1 <- 
  create_model_coefs_plot( m_responses_exp1only, 
        plot_stats = T, map_names = contrast_names_exp1,
        expand_right = 2.5, expand_top = 2, x_stat_adjust = 1.1,
        x_breaks = c(-3,-2,-1, 0,1, 2) ) + 
        xlab("Estimate (probit)")

p_m_response_exp1 <- p_m_response_exp1 + facet_wrap(~"Experiment 1") + annotate(x=-3, xend=2, y=0, yend=0, lwd=0.25, geom="segment")

p_m_response_lago <- 
  create_model_coefs_plot( m_responses_Lagoonly, 
        plot_stats = T, map_names = contrast_names_exp1,
        expand_right = 2.5, expand_top = 2, x_stat_adjust = 1.1,
        x_breaks = c(-3,-2,-1, 0,1, 2) ) + 
        xlab("Estimate (probit)")

p_m_response_lago <- p_m_response_lago + facet_wrap(~"Lago et al. (2018)") + annotate(x=-3, xend=2, y=0, yend=0, lwd=0.25, geom="segment")

p_m_response_exp1_and_lago <- ggarrange(p_m_response_exp1, p_m_response_lago, ncol = 1)

suppressWarnings({
print(p_m_response_exp1_and_lago)
})

@


\subsection{Discussion} \label{sec:exp1:discussion}

In Experiment 1, we have found number attraction effects in Turkish using genitive possessive structures, as it is also attested in \citet{LagoEtAl:2018}. To account for their findings, \citet{LagoEtAl:2018} assume a cue-based memory retrieval mechanism. That is, they assume that upon reaching the verb, the parser attempts to retrieve its agreement controller (the subject) using a cue-based retrieval mechanism \citep{LewisVasishth:2005,JagerEngelmannVasishth:2017}. The assumption is that in sentences such as \ref{item:exp1ExperimentalItems}, features such as case and number information are used to identify the agreement controller in memory. In ungrammatical sentences, when the verb bears plural agreement, no NP in memory will match both retrieval cues. However, in ungrammatical plural attractor conditions, the attractor matches one of the cues, which can lead to its erroneous retrieval on some occasions. This cannot happen in ungrammatical singular attractor conditions. This difference in the probability of erroneous retrievals is presumably what surfaced as a number agreement attraction effect, as observed in \citet{LagoEtAl:2018}, and our Experiment 1.

In their work, \citet{LagoEtAl:2018} argue that the agreement attraction in genitive-possessive structures in Turkish is due to the use of genitive case as a marker of embedded subjects in Turkish, i.e. differential subject marking (DSM) properties of Turkish \citep{kornfilt2009dom}. They argue that the genitive case in Turkish may not provide strong cue against subjecthood due to DSM while it does in English. Following this logic, we hypothesized that the other phenomenon that gives a strong clue against the subject should inhibit the illusionary dependencies as argued in \citet{nicol2016minimal}. One such phenomenon was present in the experimental items used in \citet{LagoEtAl:2018}: the morpho-phonologic ambiguity between the accusative and the possessive case. Since they use only consonant ending heads, the marking on the head is ambiguous between the accusative and the possessive marking. Following their argumentation, participants may search for other agreement controllers than the possessive marked heads when they are engaged in shallow processing and erroneously assign head as genitive marked distractor.

Nevertheless, we found that when the possessive marker is disambiguated agreement attraction does not diminish in effect size. As seen in \autoref{fig:exp1ResponseModel}, we successfully replicated the findings of \citet{LagoEtAl:2018} with disambiguated head nouns. Thus, we conclude that the morpho-phonological possessive-accusative ambiguity plays no role in number attraction in Turkish.


However, there is an alternative explanation that has yet to be ruled out: task-specific strategies. We hypothesized that readers may engage in an even shallower process in the evaluation of the sentences such as \ref{item:exp2ExperimentalItems} in which readers decide on the acceptability of the sentence with a faulty state of memory. In our model, we claim that after they read the sentence readers may end up with insufficient information to reliably judge the sentence. Upon such cases, readers may end up using extremely shallow processing methods such as matching the agreement-wise unrelated but form-wise related elements. % I should try a bit more to explain this part, I did not do a good job here.
We present our hypothesized decision tree in \autoref{fig:mptModel}

\begin{figure}[h]
    \centering
                      \begin{forest}
                  for tree = {
                  % nodes
                      draw, 
                      align=center,
                      minimum height=5ex,
                      minimum width=3em,
                      font=\linespread{0.84}\selectfont,
                  % tree
                      grow'=0,
                      parent anchor=east,
                      child  anchor=west,
                      s sep = 4mm,    
                      l sep = 12mm, 
                  % edge
                      edge = {semithick},
                  % level styles
                  if level = 0{}{rounded corners=2ex},
                  where n children=0{tier=level, sharp corners}{calign=edge midpoint},
                  % edge labels
                  EL/.style={edge label={node [pos=0.5, fill=white,
                                               font=\scriptsize\sffamily,
                                               inner sep=2pt] {$#1$}}
                                      }
                              }% end for tree
                  [,coordinate
                  [target\\ item,no edge
                      [recolection\\ certainity, EL=r
                          ["yes"]
                      ]
                      [recolection\\ uncertainity, EL=1-r,
                          [guess "yes", tier=L1, EL=g,
                              ["yes"]
                          ]
                          [guess "no", tier=L1, EL=1-g
                              ["no"]
                          ]
                      ]
                  ]
                  [,coordinate, no edge]
                  [target\\ item, no edge
                      [guess "yes", tier=L1, EL=g,
                              ["yes"]
                      ]
                      [guess "no", tier=L1, EL=1-g
                          ["no"]
                      ]
                   ]
                  ]
                      \end{forest} 
    \caption{Proposed multinomial processing tree of how people judge sentences in an agreement attraction task}
    \label{fig:mptModel}
\end{figure}

The aim of our second experiment was to test whether agreement attraction in Turkish may be an instance of a \textit{form-driven processing strategy}. Assuming that readers sometimes engage in shallow processing, they may end up with insufficient information to reliably classify a sentence as (un)acceptable. In such cases, participants may choose to classify sentences with plural-agreement-bearing verbs as acceptable if they have a memory of a nominal plural morpheme in the sentence. Such a response strategy would lead to a larger number of ‘acceptable’ responses in ungrammatical plural attractor conditions than in ungrammatical singular attractor conditions. 



\section{Experiment 2} \label{sec:exp2}

<<loadExperiment2Data>>=

fname_data2 <- "../workspace_exp2/exp_data.rds"
data_exp2 <- readRDS(file = fname_data2)
fname_form <- "../workspace_exp2/exp_form.rds"
form_exp2 <- readRDS(file = fname_form)

# compute by-subject percentages of 'yes' responses, and average RTs 
avg_by_subj2 <- data_exp2 %>%
                group_by(subject, experiment, condition, 
                         grammatical, verb_num, attractor_num) %>%
                summarize(avRT = mean(RT), 
                          p_yes = mean(ResponseYes, na.rm = T), 
                          N = sum(!is.na(ResponseYes))  )

# reformat by-subject averages to a wide format
avg_by_subj_wide2 <- avg_by_subj2 %>% 
                      mutate(expcond = paste(experiment, condition, sep="_")) %>% 
                      ungroup() %>%
                      dplyr::select(-experiment, -condition, -avRT, -N,
                                    -grammatical, -verb_num, -attractor_num) %>%
                      tidyr::spread(expcond, p_yes) %>% 
                      mutate(delta_dc = AgrAttr_d - AgrAttr_c)

@

<<badSubjects2>>=

# identify bad participants 
bad_subjects2 <- subset(avg_by_subj_wide2, delta_dc <= 0.25 ) %>% .$subject

data_exp2_clean <- data_exp2 %>% subset(!subject %in% bad_subjects2)

@

<<mergeData2>>=

df_merge_exp2 <- data_exp2_clean %>% ungroup() %>% 
                      dplyr::select(source=experiment, grammatical, attractor_num, # condition,
                                    subject, item=Item,
                                    ResponseYes, RT)
df_merge_exp2$experiment <- "Experiment 2"
df_merge_exp2$grammatical %<>% dplyr::recode("gram"="grammatical", "ungram"="ungrammatical")
df_merge_exp2$attractor_num %<>% dplyr::recode("pl"="plural", "sg"="singular")
df_merge_exp2 %<>% mutate( item = sprintf("I2[%s]", as.character(item)), subject = as.character(subject) )

df_exp2_na_nofillers <- subset(df_merge_exp2, is.na(ResponseYes))

df_merge_exp1$item %<>% as.character()
df_merged2 <- dplyr::bind_rows(df_merge_exp1, df_merge_exp2)
df_merged2 %<>% mutate( subject = as.character(subject), item = as.character(item) )

df_exp2_na_nofillers <- df_merged2 %>% subset(is.na(ResponseYes) & source != "filler")
df_merged2_nonna <- df_merged2 %>% subset(!is.na(ResponseYes))

@

In Experiment 2, we wanted to rule out the possibility of \textit{form-driven processing strategy}, namely participants deciding on the acceptability of a sentence using a memory of plural morpheme in the sentence when they do not have sufficient information to rate sentences (un)acceptable. 
 

\subsection{Participants} \label{sec:exp2:participants}

We recruited 79 undergraduate students to participate in Experiment 2 in exchange for course credit. All participants were native speakers of Turkish, with an average age of \Sexpr{round(mean(form_exp2$Age))} (range: \Sexpr{min(form_exp2$Age)} - \Sexpr{max(form_exp2$Age)}). 
Experiment were carried out following the Declaration of Helsinki and the regulations concerning ethics at research in Bo\u{g}azi\c{c}i University. All participants provided informed consent prior to their participation.


\subsection{Materials} \label{sec:exp2:materials}

We used 40 sets of sentences like
(\ref{item:exp2ExperimentalItems}), in which we manipulated
(i) the number of the attractor, and
(ii) the number agreement on the verb. 
Unlike Experiment 1, we used the verb of a nominalized relative clause (i.e. \textit{tuttukları}) as an attractor instead of a genitive marked noun. 
We took advantage of syncretism between Turkish nominal and verbal plural marker. Both of these morphemes spells-out as \textit{-lAr}, which enables us to check whether agreement attraction in Turkish can be explained by an extremely shallow dependency parsing based on the forms of morphemes rather than linguistic features.


All sentences started with a complex subject NP like \textit{`the cook that they hired'} (\textit{tuttukları aşçı}), in which the verb of the relative clause functioned as the attractor. Because the head noun was singular in all conditions, sentences with plural verb agreement were ungrammatical.  
We have used the same verbs, and have not changed the distribution of verb types. We also utilized the same or similar adverbials in length.
Relative clauses we used in this experiment are all object relative clauses, and they are all marked with canonical \textit{-dIK} nominalizer. Since Turkish is a pro-drop language, we also dropped the subject within the embedded clause, thus ending up with a one-word object relative clause whose head is the controller of the number agreement on the matrix verb. One example set of experimental items can be seen in \ref{item:exp2ExperimentalItems}.


\ex. \label{item:exp2ExperimentalItems}
%
\a. \textsc{Plural Attractor, Ungrammatical (Plural Verb)}\label{item:exp2expitem-plpl}\\ 
  \gll *[Tut-tuk-lar-ı \textbf{aşcı}] mutfak-ta sürekli \textbf{zıpla-dı-lar}.\\ 
  hire-\textsc{nmlz}-\textsc{pl}-\textsc{poss}  cook kitchen-\textsc{loc} non-stop  jump-\textsc{pst}-\textsc{pl}.\\
  \glt \textit{`The cook that they hired were jumping in the kitchen non-stop.'}
%
\b. \textsc{Plural Attractor, Grammatical (Singular Verb)}\label{item:exp2expitem-plsg}\\ 
  \gll [Tut-tuk-lar-ı \textbf{aşcı}] mutfak-ta sürekli \textbf{zıpla-dı}.\\ 
  hire-\textsc{nmlz}-\textsc{pl}-\textsc{poss}  cook kitchen-\textsc{loc} non-stop  jump-\textsc{pst}.\\
  \glt \textit{`The cook that they hired was jumping in the kitchen non-stop.'}
%
\c. \textsc{Singular Attractor, Ungrammatical (Plural Verb)}\label{item:exp2expitem-sgpl}\\
  \gll *[Tut-tuğ-u \textbf{aşcı}] mutfak-ta sürekli \textbf{zıpla-dı-lar}.\\ 
  hire-\textsc{nmlz}-\textsc{poss}  cook kitchen-\textsc{loc} non-stop  jump-\textsc{pst}-\textsc{pl}.\\
  \glt \textit{`The cook that they hired were jumping in the kitchen non-stop.'}
%
\d. \textsc{Singular Attractor, Grammatical (Singular Verb)}\label{item:exp2expitem-sgsg}\\ 
  \gll [Tut-tuğ-u \textbf{aşcı}] mutfak-ta sürekli \textbf{zıpla-fı}.\\ 
  hire-\textsc{nmlz}-\textsc{poss}  cook kitchen-\textsc{loc} non-stop  jump-\textsc{pst}.\\
  \glt \textit{`The cook that they hired was jumping in the kitchen non-stop.'}

In addition to the experimental items, we used 40 filler sentences of two types, both of which starts with an object relative clause, as illustrated in (\ref{item:exp2FillerItems}). Similar to Experiment 1, our filler items included 20 grammatical sentences with an overtly plural marked verbs, and 20 ungrammatical sentences with no overt plural marking, thus singular. 
This was done in order to discourage participants from using a strategy based on verb number. 
In all of our filler sentences, the dependency between the first complex NP subject modified with an object relative clause and its verb resolved in an adverbial embedded sentence. 
In grammatical fillers, we have used intransitive verbs with a pro-dropped subject as in (\ref{item:exp2FillerItems_plural}). 
In ungrammatical fillers, we created the ungrammaticality by placing an adverbial between the bare nominal object and the verb as in (\ref{item:exp2FillerItems_singular}). 

\ex. \label{item:exp2FillerItems}
%
\a. \label{item:exp2FillerItems_plural} \textsc{Grammatical Filler (Plural Verb)}\\ 
  \gll Oku-t-tuk-lar-ı öğrenci başarılı ol-unca mutlu ol-du-lar.\\ 
  read-\textsc{caus}-\textsc{nmlz}-\textsc{pl}-\textsc{poss}  student successful be-\textsc{nmlz} happy be-\textsc{pst}-\textsc{pl}.\\
  \glt `When the student they sponsored become successful, they became happy.' 
%
\b. \label{item:exp2FillerItems_singular} \textit{Ungrammatical Filler (Singular Verb)}\\ 
  \gll *Kandır-dığ-ı adam öde-me-yince bulaşık saatlerce yıka-dı.\\ 
  trick-\textsc{nmlz}-\textsc{poss}  man pay-\textsc{neg}-\textsc{nmlz} dish for.hours clean-\textsc{pst}.\\
  \glt Intended:`When the man he tricked did not pay, he cleaned dishes for hours.'

\subsection{Procedure} \label{sec:exp2:procedure}

The experiment was run online, using the web-based platform Ibex Farm (\url{http://spellout.net/ibexfarm/}). For each participant, experiment took approximately 25 minutes to complete.
Participants were asked to provide information regarding their native language and age. They were also asked for their consent to participate in the experiment.
Prior to experimental items, participants read the instructions, and were given 9 practice items with feedback on their accuracy.
Each trial began with a blank screen for 600 ms, followed by a word-by-word RSVP presentantion of the sentence in the center of the screen, followed by an acceptability judgment. Sentences were presented in 30pt font size, and at a rate of 400 ms per word. Between each word, participants saw a blank screen for 100 ms. Participants pressed the key `P' for `\textit{acceptable}' and `Q' for `\textit{unacceptable}'.
Within instructions, they were told to provide an acceptability rating before 5,000 ms deadline. During the experiment, they were reminded to respondfaster if they did not respond within 5,000 ms.

Participants saw 40 experimental and 40 filler sentences. Experimental sentences were distributed among four different lists according to a Latin-square design. Every participant saw one version of the experiment with a specific list and one item per condition.

\subsection{Analysis} \label{sec:exp2:analysis}



<<computeAverages2>>=

avg_clean2 <- list()
avg_clean2$resp <- df_merged2_nonna %>% 
              plyr::ddply(c("experiment"), function(df) {
              df %>% se_cousineau(n_conditions = 4, subject, DV = ResponseYes, 
                           group = c("experiment", "source", "grammatical", "attractor_num"), 
                           is_proportion = TRUE)
})

avg_clean2$rt <- df_merged2_nonna %>%
              plyr::ddply(c("experiment"), function(df) {
              df %>% se_cousineau(n_conditions = 4, subject, DV = RT, 
                           group = c("experiment", "source", "grammatical", "attractor_num"), 
                           is_proportion = FALSE)
})

# TODO: Code ResponseCorrect and re-enable
# avg_clean$rt_correct <- df_merged2_nonna %>% subset(ResponseCorrect) %>%
#               plyr::ddply(c("experiment"), function(df) {
#               df %>% se_cousineau(n_conditions = 4, subject, DV = RT, 
#                            group = c("experiment", "source", "grammatical", "attractor_num"), 
#                            is_proportion = FALSE)
# })

avg_exp2 <- avg_clean2 %>% lapply(function(df) { df %>% subset(is.na(source) | source != "filler") })
#avg_fillers <- avg_clean %>% lapply(function(df) { df %>% subset(source == "filler") })


@

In our analysis, we used the items from Experiment 1, as well as the items from Experiment 2. this decision was made to answer our hypothesis that whether or not participants use the form of the plural suffix rather than the linguistic features. A presence of interaction between the attractor type (\textit{nominal} vs. \textit{verbal}) and the agreement attraction effect would indicate that people use the linguistic features rather than the form of the plural suffix. 

Similar to Experiment 1, we removed the data for all participants who did not exceed the threshold of 25 percentage points in `yes' responses between the grammatical condition and the ungrammatical condition with singular attractors. As a result, we excluded \Sexpr{stopifnot(length(bad_subjects2) == 1)} one participant from the Experiment 2, and \Sexpr{length(bad_subjects)} participant from the Experiment 1.

We used R packages brms \citep{R-brms_b} and rstan \citep{R-stan} to fit Bayesian hierarchical models \citep[e.g.,][]{GelmanHill:2007}. We aalyzed only experimental sentences, and used (i) grammaticality of the sentence, (ii) attractor number, and (iii) type of the plural suffix (i.e., experiment), as well as their interactions as predictors. 
Moreover, we used by-participant and by-item intercepts and slopes for all predictors.
Data for Experiment 2, along with our analysis scripts can be found in \url{https://github.com/utkuturk/orc-attractor_numberattraction}.

%Across participants, a total \Sexpr{sum(is.na(df_exp2_na_nofillers$ResponseYes))} items were not responded to before the 5 second deadline by \Sexpr{length(unique(df_exp2_na_nofillers$subject))} different participants. These items were not included in the analysis. 

\subsection{Results} \label{sec:exp2:results}


<<curEntries>>=


exp2_cur_entry1 = avg_exp2$resp %>% filter(experiment == "Experiment 2", grammatical == "ungrammatical", attractor_num == "plural")
exp2_cur_entry2 = avg_exp2$resp %>% filter(experiment == "Experiment 2", grammatical == "ungrammatical", attractor_num == "singular")

exp2_cur_entry3 = avg_exp2$resp %>% filter(experiment == "Experiment 2", grammatical == "grammatical", attractor_num == "singular")
exp2_cur_entry4 = avg_exp2$resp %>% filter(experiment == "Experiment 2", grammatical == "grammatical", attractor_num == "plural")


@



\autoref{fig:exp2AvgResponse} shows the average proportions of 'acceptable' responses by experimental conditions for Experiment 2. 
It shows that ungrammatical sentences with plural attractors are rated as acceptable 
(M = \Sexpr{exp2_cur_entry1$M}, 
SE = \Sexpr{exp2_cur_entry1$SE}) 
as their counterparts with singular attractors 
(M = \Sexpr{exp2_cur_entry2$M}, 
SE = \Sexpr{exp2_cur_entry2$SE}). The lack of effect (\Sexpr{sprintf("%0.2f", exp2_cur_entry1$M-exp2_cur_entry2$M)}) compared to the magnitude of the effect in Experiment 1 (\Sexpr{sprintf("%0.2f", cur_entry1$M-cur_entry2$M)}) indicates that the verbal plural morpheme does not trigger an illusionary agreement.
%
Accuracy rates for grammatical conditions were nearly equal
(M = \Sexpr{exp2_cur_entry3$M} and \Sexpr{exp2_cur_entry4$M}, 
SE = \Sexpr{exp2_cur_entry3$SE} and \Sexpr{exp2_cur_entry4$SE}, for singular and plural attractors respectively). 


<<exp2AvgResponse, fig.cap='Estimates and 95\\% credible intervals for the regression coefficients for Experiment 1 and Experiment 2.  Within-subject 95\\% confidence intervals in brackets \\cite{Cousineau:2005,Morey:2008}.', fig.height=3, fig.align='center'>>=

avg_exp2 <- avg_clean2$resp %>% subset(is.na(source) | source != "filler") %>% subset(experiment == "Experiment 2")
avg_fillers2 <- avg_clean2$resp %>% subset(source == "filler") %>% subset(experiment == "Experiment 2")

p_avg_resp2 <- ggplot(avg_exp2, aes(grammatical, M, #linetype = attractor_num, 
                                    color = attractor_num, group = attractor_num)) + 
                geom_point(position = pd) + geom_line(position = pd) + 
                facet_wrap(~experiment) +
                theme_bw() + theme( strip.background = element_rect(fill="white") ) +
                xlab("") + ylab("Percentage 'acceptable'")

p_avg_resp2 <- p_avg_resp2 + geom_errorbar(aes(ymin = M - 1.96*SE, ymax = M + 1.96*SE), width = 0.1, position = pd)
p_avg_resp2 <- p_avg_resp2 + scale_y_continuous(labels=scales::percent, limits = c(0, 1))
p_avg_resp2 <- p_avg_resp2 + scale_color_discrete(name = "Attractor Number")

print(p_avg_resp2)

@




<<Model, include=FALSE>>=

df_merged2 %<>% within(., {
  cGrammatical <- ifelse(grammatical == "grammatical", .5, -.5)
  cUngrammatical <- ifelse(grammatical == "ungrammatical", .5, -.5)
  cAttractorPlural <- ifelse(attractor_num == "plural", .5, -.5)
  cVerbalAttractor <- ifelse(experiment == "Experiment 2", .5, -.5)
})
df_merged_nofillers2 <- df_merged2 %>% subset(is.na(source) | source != "filler")

# ## test model parameterization using a simple GLM first
# m <- glm(ResponseYes ~ cVerbalAttractor * cUngrammatical * cAttractorPlural,
#          data = df_merged_nofillers2,
#          family = binomial("probit"))
# summary(m)

n_chains <- 4
n_cores <- 4
n_iter <- 2000


library(brms)

fname_exp2_responses <- "../workspace_exp2/fit_responses"
m_responses2 <- brm(ResponseYes ~ cVerbalAttractor * cUngrammatical * cAttractorPlural + 
                                 (cUngrammatical * cAttractorPlural + 1| subject) +
                                 (cUngrammatical * cAttractorPlural + 1| item),
                   data = df_merged_nofillers2 %>% subset(!is.na(ResponseYes)),
                   family = bernoulli("probit"),
                   file = fname_exp2_responses, 
                   chains = n_chains, cores = n_cores, iter = n_iter)

fname_exp2only_responses <- "../workspace_exp2/fit_responses_exp2only"
m_responses2_exp2only <- brm(ResponseYes ~ cUngrammatical * cAttractorPlural + 
                                 (cUngrammatical * cAttractorPlural + 1| subject) +
                                 (cUngrammatical * cAttractorPlural + 1| item),
                   data = df_merged_nofillers2 %>% 
                              subset(!is.na(ResponseYes)) %>% 
                              subset(experiment == "Experiment 2"),
                   family = bernoulli("probit"),
                   file = fname_exp2only_responses, 
                   chains = n_chains, cores = n_cores, iter = n_iter)


 model2_results_table <- fixef(m_responses2, summary = T, robust = F) %>% 
  as.data.frame() #%>% tibble::rownames_to_column("variables")


 @


A Bayesian GLM assuming a Bernoulli distribution with a probit-link function was fit to participants' `acceptable' responses. The model's estimates and 95\% credible intervals are shown in \autoref{fig:exp2ResponseModel}. 
The main effect of \textit{ungrammaticality} (\Sexpr{print_estimate_with_ci( m_responses2, 'cUngrammatical' )}) indicates that, 
on average, participants were quite good at distinguishing between grammatical and ungrammatical sentences. 
Meanwhile, there was no evidence for an interaction between \textit{ungrammaticality} and \textit{attractor number} (\Sexpr{print_estimate_with_ci( m_responses2, 'cUngrammatical:cAttractorPlural')}), indicating 
a similar effect of attractor number in ungrammatical conditions compared to grammatical conditions, and thus no number agreement attraction effect.
Importantly, the negative effect between \textit{the presence of the verbal plural}, \textit{ungrammaticality} and \textit{attractor number} (\Sexpr{print_estimate_with_ci( m_responses2, 'cVerbalAttractor:cUngrammatical:cAttractorPlural')}) indicated that the plural morpheme on the verb of the object relative clause lowered the agreement attraction effects.





<<exp2ResponseModel, fig.cap='Estimates and 95\\% credible intervals for the regression coefficients for a model of Experiment 1 and Experiment 2.', fig.height=3, fig.align='center'>>=

contrast_names2_le <- c("cUngrammatical" = "Ungrammaticality",
                    "cAttractorPlural" = "Plural Attactor",
                    "cVerbalAttractor" = "Verbal Attractor",
                    "cUngrammatical:cAttractorPlural" = "Ungrammaticality * Plural Attractor",
                    "cVerbalAttractor:cUngrammatical" = "Ungrammaticality * Verbal Attractor",
                    "cVerbalAttractor:cAttractorPlural" = "Verbal Attractor * Plural Attractor",
                    "cVerbalAttractor:cUngrammatical:cAttractorPlural" = "Verbal Attractor * Ungrammaticality * Plural Attractor")

p_m_response_exp2 <- 
  create_model_coefs_plot( m_responses2, 
        plot_stats = T, map_names = contrast_names2_le,
        expand_right = 4.5, expand_top = 1.5, x_stat_adjust = .75,
        x_breaks = c(-3,-2,-1, 0, 1) ) + 
        xlab("Estimate (probit)")
    
p_m_response_exp2 <- p_m_response_exp2 + annotate(x=-3, xend=1, y=0, yend=0, lwd=0.25, geom="segment")
print(p_m_response_exp2)
@



<<exp2ResponseModelExp2Only, fig.cap='Estimates and 95\\% credible intervals for the regression coefficients for Experiment 2.', fig.height=1.5, fig.align='center'>>=

p_m_response_exp2_exp2only <- 
  create_model_coefs_plot( m_responses2_exp2only, 
        plot_stats = T, map_names = contrast_names2_le,
        expand_right = 4.5, expand_top = 1.5, x_stat_adjust = .75,
        x_breaks = c(-3,-2,-1, 0, 1) ) + 
        xlab("Estimate (probit)")
    
p_m_response_exp2only <- p_m_response_exp2_exp2only + annotate(x=-3, xend=1, y=0, yend=0, lwd=0.25, geom="segment")
print(p_m_response_exp2only)

@



\subsection{Discussion} \label{sec:exp2:discussion}


In Experiment 2, we could not find any effect of agreement attraction in the acceptability ratings of ungrammatical conditions with a verbal plural attractor. However, number agreement attractions were observed when the attractors were nominal. Even though the forms of the two plural morphemes are the same form-wise, there is a distinct difference between the results of two experiments. One of the indications of zero-effect with verbal plural morpheme is that readers do not make decisions solely based on the form of the elements. This finding contradicts our hypothesized form-driven processing strategy and supports an account of agreement attraction based on the use of abstract linguistic features, rather than mere form.

However, results may be more telling with regards to the other theories of agreement attraction. These results seem unexpected within the cue-based retrieval mechanisms. Even though the root of the attractor is verbal, the morpheme is the same with the third person plural possessive marker since the relative clauses in Turkish are always nominalized and the subject is marked with the genitive case. The findings of this experiment indicate towards more fine-grained features needs to be utilized. One other possible explanation within the cue-based retrieval models can be formed around the status of agreement markers. One can say that the agreement process is completed in the verbal \textit{-lAr}; in other words, it is not the triggering morpheme but the probe of the agreement. This difference would mean that verbal \textit{-lAr} should not start any search for dependency resolution. In contrast to verbal \textit{-lAr}, the plural morpheme on the genitive is supposed to be triggering part of the agreement, not the probe. However, in Turkish embedded clauses, where genitive subjects can be seen, the number agreement works differently than the matrix level agreement. When the genitive subject of an embedded clause is marked with plural it is ungrammatical to have plural marking on the verb. 
This prohibition in return means that the genitive subjects should not create an expectation for a plural marked verb, which was believed to be the reason for the agreement attraction in \citet{LagoEtAl:2018}.


As for the marking and morphing theories, the results of Experiment 2 are completely expected and mitigated by the syntactic depth effects. Due to the genitive possessor's limited inner complexity compared to that of relative clause modifiers, marking and morphing theories would expect higher contribution from the genitive attractors to the final representation of number information. 


\section{General Discussion} \label{sec:general_discussion}



\bibliography{new-references,library}

\end{document}

%
% Please see the package documentation for more information
% on the APA6 document class:
%
% http://www.ctan.org/pkg/apa6
%